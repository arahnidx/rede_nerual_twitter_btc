{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c9ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ef3dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('twitter_BTC_Users_3Months_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408222dd",
   "metadata": {},
   "source": [
    "## Formatando as mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c240429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>followers</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1454105101988253701</td>\n",
       "      <td>Someone just $ 183m off into cold storage !üê≥üê≥üê≥...</td>\n",
       "      <td>BTC_Archive</td>\n",
       "      <td>960082</td>\n",
       "      <td>7580</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1453718525952999437</td>\n",
       "      <td>personally $ 1 . 091 Billion ( 17 , 732 )</td>\n",
       "      <td>BTC_Archive</td>\n",
       "      <td>960082</td>\n",
       "      <td>2185</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1453717422402248718</td>\n",
       "      <td>: I personally 17 , 732 $ with $ 9 , 882 avera...</td>\n",
       "      <td>BTC_Archive</td>\n",
       "      <td>960082</td>\n",
       "      <td>6554</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1453689564586037251</td>\n",
       "      <td>Only they seem to apply to .</td>\n",
       "      <td>BTC_Archive</td>\n",
       "      <td>960082</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1453673450229354497</td>\n",
       "      <td>there is no hate . It ' s just not comparable ...</td>\n",
       "      <td>BTC_Archive</td>\n",
       "      <td>960082</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date                   id  \\\n",
       "0           0  2021-10-29  1454105101988253701   \n",
       "1           1  2021-10-28  1453718525952999437   \n",
       "2           2  2021-10-28  1453717422402248718   \n",
       "3           3  2021-10-28  1453689564586037251   \n",
       "4           4  2021-10-28  1453673450229354497   \n",
       "\n",
       "                                                text     username  followers  \\\n",
       "0  Someone just $ 183m off into cold storage !üê≥üê≥üê≥...  BTC_Archive     960082   \n",
       "1          personally $ 1 . 091 Billion ( 17 , 732 )  BTC_Archive     960082   \n",
       "2  : I personally 17 , 732 $ with $ 9 , 882 avera...  BTC_Archive     960082   \n",
       "3                       Only they seem to apply to .  BTC_Archive     960082   \n",
       "4  there is no hate . It ' s just not comparable ...  BTC_Archive     960082   \n",
       "\n",
       "   favorites  retweets  \n",
       "0       7580       769  \n",
       "1       2185       190  \n",
       "2       6554       557  \n",
       "3          6         0  \n",
       "4          7         0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk \n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def cleaner(text):\n",
    "    text = re.sub(\"@[A-Za-z0-9]+\",\"\",text) #Remove @ sign\n",
    "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text) #Remove http links\n",
    "    text = \" \".join(text.split())\n",
    "    text = ''.join(c for c in text if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    text = text.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "    return text\n",
    "data['text'] = data['text'].map(lambda x: cleaner(x))\n",
    "data['date'] = pd.to_datetime(data['date']).dt.date\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8a34b",
   "metadata": {},
   "source": [
    "## An√°lise vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6d8bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = []\n",
    "# Declare variables for scores\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "for i in range(data['text'].shape[0]):\n",
    "#print(analyser.polarity_scores(sentiments_pd['text'][i]))\n",
    "    compound = analyzer.polarity_scores(data['text'][i])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(data['text'][i])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(data['text'][i])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(data['text'][i])[\"neg\"]\n",
    "    \n",
    "    scores.append({\"Compound\": compound,\n",
    "                       \"Positive\": pos,\n",
    "                       \"Negative\": neg,\n",
    "                       \"Neutral\": neu\n",
    "                  }) \n",
    "sentiments_score = pd.DataFrame.from_dict(scores)\n",
    "df_sentiment = data.join(sentiments_score)\n",
    "\n",
    "df_sentiment['Score Positive Retweet'] = (df_sentiment['retweets'] + df_sentiment['favorites']) * df_sentiment['Positive']\n",
    "df_sentiment['Score Negative Retweet'] = (df_sentiment['retweets'] + df_sentiment['favorites']) * df_sentiment['Negative']\n",
    "df_sentiment['Score Neutral Retweet'] = (df_sentiment['retweets'] + df_sentiment['favorites']) * df_sentiment['Neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4909f7a",
   "metadata": {},
   "source": [
    "## Removendo colunas desnecess√°rias e mudando outras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9857b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment.index = range(df_sentiment.shape[0])\n",
    "df_sentiment.columns.name = 'Id'\n",
    "df_sentiment.drop(columns =['username', 'followers', 'Unnamed: 0', 'id'], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "data = df_sentiment.groupby(['date']).agg(['mean','count'])\n",
    "data.columns = [ ' '.join(str(i) for i in col) for col in data.columns]\n",
    "data.reset_index(inplace=True)\n",
    "data = data[:-1]\n",
    "data.drop(columns = \n",
    "         ['favorites count', 'retweets count', 'Compound count', 'Positive count', 'Negative count', 'Neutral count', \n",
    "         'Score Positive Retweet count', 'Score Negative Retweet count', 'Score Neutral Retweet count'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0249cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>favorites mean</th>\n",
       "      <th>retweets mean</th>\n",
       "      <th>Compound mean</th>\n",
       "      <th>Positive mean</th>\n",
       "      <th>Negative mean</th>\n",
       "      <th>Neutral mean</th>\n",
       "      <th>Score Positive Retweet mean</th>\n",
       "      <th>Score Negative Retweet mean</th>\n",
       "      <th>Score Neutral Retweet mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>233.714286</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.949429</td>\n",
       "      <td>4.973619</td>\n",
       "      <td>9.916571</td>\n",
       "      <td>254.132190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>163.846154</td>\n",
       "      <td>21.153846</td>\n",
       "      <td>0.178592</td>\n",
       "      <td>0.060692</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>14.974769</td>\n",
       "      <td>2.195769</td>\n",
       "      <td>167.829462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>207.900000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.906300</td>\n",
       "      <td>4.014000</td>\n",
       "      <td>5.491200</td>\n",
       "      <td>227.894800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>0.079550</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>314.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>255.650000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>0.191020</td>\n",
       "      <td>0.085850</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.870100</td>\n",
       "      <td>23.523450</td>\n",
       "      <td>21.401850</td>\n",
       "      <td>259.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>20.481481</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>0.933630</td>\n",
       "      <td>2.355926</td>\n",
       "      <td>1.938296</td>\n",
       "      <td>143.182852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>169.714286</td>\n",
       "      <td>21.452381</td>\n",
       "      <td>-0.031840</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.932667</td>\n",
       "      <td>22.493643</td>\n",
       "      <td>1.318071</td>\n",
       "      <td>167.355357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>263.517241</td>\n",
       "      <td>33.068966</td>\n",
       "      <td>-0.036252</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.944034</td>\n",
       "      <td>1.644621</td>\n",
       "      <td>37.841379</td>\n",
       "      <td>257.118172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>313.937500</td>\n",
       "      <td>46.312500</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>0.025354</td>\n",
       "      <td>0.943625</td>\n",
       "      <td>4.582375</td>\n",
       "      <td>0.537896</td>\n",
       "      <td>355.129729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>220.381579</td>\n",
       "      <td>23.934211</td>\n",
       "      <td>-0.009863</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>0.956987</td>\n",
       "      <td>0.656987</td>\n",
       "      <td>1.042737</td>\n",
       "      <td>242.616092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  favorites mean  retweets mean  Compound mean  Positive mean  \\\n",
       "0    2021-07-01      233.714286      35.333333      -0.001395       0.023952   \n",
       "1    2021-07-02      163.846154      21.153846       0.178592       0.060692   \n",
       "2    2021-07-03      207.900000      29.500000       0.071900       0.083300   \n",
       "3    2021-07-04      273.750000      41.250000       0.079550       0.019000   \n",
       "4    2021-07-05      255.650000      48.100000       0.191020       0.085850   \n",
       "..          ...             ...            ...            ...            ...   \n",
       "116  2021-10-25      127.000000      20.481481       0.064531       0.038833   \n",
       "117  2021-10-26      169.714286      21.452381      -0.031840       0.034548   \n",
       "118  2021-10-27      263.517241      33.068966      -0.036252       0.021552   \n",
       "119  2021-10-28      313.937500      46.312500       0.030342       0.031021   \n",
       "120  2021-10-29      220.381579      23.934211      -0.009863       0.020158   \n",
       "\n",
       "     Negative mean  Neutral mean  Score Positive Retweet mean  \\\n",
       "0         0.026571      0.949429                     4.973619   \n",
       "1         0.013308      0.926000                    14.974769   \n",
       "2         0.010400      0.906300                     4.014000   \n",
       "3         0.000000      0.981000                     0.171000   \n",
       "4         0.044100      0.870100                    23.523450   \n",
       "..             ...           ...                          ...   \n",
       "116       0.027481      0.933630                     2.355926   \n",
       "117       0.032833      0.932667                    22.493643   \n",
       "118       0.034483      0.944034                     1.644621   \n",
       "119       0.025354      0.943625                     4.582375   \n",
       "120       0.022868      0.956987                     0.656987   \n",
       "\n",
       "     Score Negative Retweet mean  Score Neutral Retweet mean  \n",
       "0                       9.916571                  254.132190  \n",
       "1                       2.195769                  167.829462  \n",
       "2                       5.491200                  227.894800  \n",
       "3                       0.000000                  314.829000  \n",
       "4                      21.401850                  259.014900  \n",
       "..                           ...                         ...  \n",
       "116                     1.938296                  143.182852  \n",
       "117                     1.318071                  167.355357  \n",
       "118                    37.841379                  257.118172  \n",
       "119                     0.537896                  355.129729  \n",
       "120                     1.042737                  242.616092  \n",
       "\n",
       "[121 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7237f5b",
   "metadata": {},
   "source": [
    "## Acessando BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "346a975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Id</th>\n",
       "      <th>movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Id   movement\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           0\n",
       "4           1\n",
       "..        ...\n",
       "116         0\n",
       "117         0\n",
       "118         1\n",
       "119         1\n",
       "120         0\n",
       "\n",
       "[121 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moeda = ['BTC-USD']\n",
    "btc = yf.download(moeda, start='2021-07-01',\n",
    "                end='2021-10-30')\n",
    "\n",
    "\n",
    "btc ['Return'] = btc['Close'].pct_change()*100\n",
    "btc ['price dir'] = btc['Close'].diff()\n",
    "btc ['movement'] =  np.where(btc['price dir'] > 0, 1,0)\n",
    "\n",
    "\n",
    "#btc = btc[1:]\n",
    "btc.index = range(btc.shape[0])\n",
    "btc.columns.name = 'Id'\n",
    "btc_movement = btc.copy()\n",
    "btc.drop(columns =['movement'], inplace = True)\n",
    "\n",
    "btc_movement = btc_movement[1:]\n",
    "btc_movement.index = range(btc_movement.shape[0])\n",
    "btc_movement.columns.name = 'Id'\n",
    "btc_movement.drop(columns =['Open', 'High','Low', 'Close', 'Adj Close', 'Volume', 'Return', 'price dir'], inplace = True)\n",
    "\n",
    "\n",
    "btc = btc.join(btc_movement)\n",
    "btc = btc.replace(np.nan,0)\n",
    "btc_movement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f6b6ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Id</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>price dir</th>\n",
       "      <th>movement</th>\n",
       "      <th>sma5</th>\n",
       "      <th>sma10</th>\n",
       "      <th>sma15</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema10</th>\n",
       "      <th>ema15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35035.984375</td>\n",
       "      <td>35035.984375</td>\n",
       "      <td>32883.781250</td>\n",
       "      <td>33572.117188</td>\n",
       "      <td>33572.117188</td>\n",
       "      <td>37838957079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33549.601562</td>\n",
       "      <td>33939.589844</td>\n",
       "      <td>32770.679688</td>\n",
       "      <td>33897.046875</td>\n",
       "      <td>33897.046875</td>\n",
       "      <td>38728974942</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>324.929688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33854.421875</td>\n",
       "      <td>34909.261719</td>\n",
       "      <td>33402.695312</td>\n",
       "      <td>34668.546875</td>\n",
       "      <td>34668.546875</td>\n",
       "      <td>24383958643</td>\n",
       "      <td>2.276009</td>\n",
       "      <td>771.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34665.566406</td>\n",
       "      <td>35937.566406</td>\n",
       "      <td>34396.476562</td>\n",
       "      <td>35287.781250</td>\n",
       "      <td>35287.781250</td>\n",
       "      <td>24924307911</td>\n",
       "      <td>1.786156</td>\n",
       "      <td>619.234375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35284.343750</td>\n",
       "      <td>35284.343750</td>\n",
       "      <td>33213.660156</td>\n",
       "      <td>33746.003906</td>\n",
       "      <td>33746.003906</td>\n",
       "      <td>26721554282</td>\n",
       "      <td>-4.369154</td>\n",
       "      <td>-1541.777344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34234.299219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34234.299219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>63032.761719</td>\n",
       "      <td>63229.027344</td>\n",
       "      <td>59991.160156</td>\n",
       "      <td>60363.792969</td>\n",
       "      <td>60363.792969</td>\n",
       "      <td>34878965587</td>\n",
       "      <td>-4.244985</td>\n",
       "      <td>-2676.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61284.067187</td>\n",
       "      <td>62246.503125</td>\n",
       "      <td>61047.655990</td>\n",
       "      <td>61497.424873</td>\n",
       "      <td>61190.595303</td>\n",
       "      <td>60161.459408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>60352.000000</td>\n",
       "      <td>61435.183594</td>\n",
       "      <td>58208.187500</td>\n",
       "      <td>58482.386719</td>\n",
       "      <td>58482.386719</td>\n",
       "      <td>43657076893</td>\n",
       "      <td>-3.116779</td>\n",
       "      <td>-1881.406250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60842.091406</td>\n",
       "      <td>61939.380078</td>\n",
       "      <td>61210.411198</td>\n",
       "      <td>60492.412155</td>\n",
       "      <td>60698.193743</td>\n",
       "      <td>59951.575322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>58470.730469</td>\n",
       "      <td>62128.632812</td>\n",
       "      <td>58206.917969</td>\n",
       "      <td>60622.136719</td>\n",
       "      <td>60622.136719</td>\n",
       "      <td>45257083247</td>\n",
       "      <td>3.658794</td>\n",
       "      <td>2139.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60687.795312</td>\n",
       "      <td>61798.985938</td>\n",
       "      <td>61425.147135</td>\n",
       "      <td>60535.653676</td>\n",
       "      <td>60684.365193</td>\n",
       "      <td>60035.395496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>60624.871094</td>\n",
       "      <td>62927.609375</td>\n",
       "      <td>60329.964844</td>\n",
       "      <td>62227.964844</td>\n",
       "      <td>62227.964844</td>\n",
       "      <td>36856881767</td>\n",
       "      <td>2.648914</td>\n",
       "      <td>1605.828125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60947.221094</td>\n",
       "      <td>61595.583203</td>\n",
       "      <td>61752.243229</td>\n",
       "      <td>61099.757399</td>\n",
       "      <td>60965.019675</td>\n",
       "      <td>60309.466665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>62239.363281</td>\n",
       "      <td>62330.144531</td>\n",
       "      <td>60918.386719</td>\n",
       "      <td>61888.832031</td>\n",
       "      <td>61888.832031</td>\n",
       "      <td>32157938616</td>\n",
       "      <td>-0.544985</td>\n",
       "      <td>-339.132812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60717.022656</td>\n",
       "      <td>61185.182813</td>\n",
       "      <td>61771.902083</td>\n",
       "      <td>61362.782276</td>\n",
       "      <td>61132.985558</td>\n",
       "      <td>60506.887335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Id           Open          High           Low         Close     Adj Close  \\\n",
       "0    35035.984375  35035.984375  32883.781250  33572.117188  33572.117188   \n",
       "1    33549.601562  33939.589844  32770.679688  33897.046875  33897.046875   \n",
       "2    33854.421875  34909.261719  33402.695312  34668.546875  34668.546875   \n",
       "3    34665.566406  35937.566406  34396.476562  35287.781250  35287.781250   \n",
       "4    35284.343750  35284.343750  33213.660156  33746.003906  33746.003906   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "117  63032.761719  63229.027344  59991.160156  60363.792969  60363.792969   \n",
       "118  60352.000000  61435.183594  58208.187500  58482.386719  58482.386719   \n",
       "119  58470.730469  62128.632812  58206.917969  60622.136719  60622.136719   \n",
       "120  60624.871094  62927.609375  60329.964844  62227.964844  62227.964844   \n",
       "121  62239.363281  62330.144531  60918.386719  61888.832031  61888.832031   \n",
       "\n",
       "Id        Volume    Return    price dir  movement          sma5         sma10  \\\n",
       "0    37838957079  0.000000     0.000000       1.0           NaN           NaN   \n",
       "1    38728974942  0.967856   324.929688       1.0           NaN           NaN   \n",
       "2    24383958643  2.276009   771.500000       1.0           NaN           NaN   \n",
       "3    24924307911  1.786156   619.234375       0.0           NaN           NaN   \n",
       "4    26721554282 -4.369154 -1541.777344       1.0  34234.299219           NaN   \n",
       "..           ...       ...          ...       ...           ...           ...   \n",
       "117  34878965587 -4.244985 -2676.031250       0.0  61284.067187  62246.503125   \n",
       "118  43657076893 -3.116779 -1881.406250       1.0  60842.091406  61939.380078   \n",
       "119  45257083247  3.658794  2139.750000       1.0  60687.795312  61798.985938   \n",
       "120  36856881767  2.648914  1605.828125       0.0  60947.221094  61595.583203   \n",
       "121  32157938616 -0.544985  -339.132812       0.0  60717.022656  61185.182813   \n",
       "\n",
       "Id          sma15          ema5         ema10         ema15  \n",
       "0             NaN           NaN           NaN           NaN  \n",
       "1             NaN           NaN           NaN           NaN  \n",
       "2             NaN           NaN           NaN           NaN  \n",
       "3             NaN           NaN           NaN           NaN  \n",
       "4             NaN  34234.299219           NaN           NaN  \n",
       "..            ...           ...           ...           ...  \n",
       "117  61047.655990  61497.424873  61190.595303  60161.459408  \n",
       "118  61210.411198  60492.412155  60698.193743  59951.575322  \n",
       "119  61425.147135  60535.653676  60684.365193  60035.395496  \n",
       "120  61752.243229  61099.757399  60965.019675  60309.466665  \n",
       "121  61771.902083  61362.782276  61132.985558  60506.887335  \n",
       "\n",
       "[122 rows x 15 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas_ta as ta\n",
    "\n",
    "#simple movement average\n",
    "btc['sma5'] = btc.ta.sma(length=5)\n",
    "btc['sma10'] = btc.ta.sma(length=10)\n",
    "btc['sma15'] = btc.ta.sma(length=15)\n",
    "\n",
    "#exponencial movement average\n",
    "btc['ema5'] = btc.ta.ema(length=5)\n",
    "btc['ema10'] = btc.ta.ema(length=10)\n",
    "btc['ema15'] = btc.ta.ema(length=15)\n",
    "\n",
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce8027dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Id</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>price dir</th>\n",
       "      <th>movement</th>\n",
       "      <th>sma5</th>\n",
       "      <th>...</th>\n",
       "      <th>std 5</th>\n",
       "      <th>std 10</th>\n",
       "      <th>std 15</th>\n",
       "      <th>prop</th>\n",
       "      <th>move -1</th>\n",
       "      <th>move -2</th>\n",
       "      <th>move -3</th>\n",
       "      <th>MM 5</th>\n",
       "      <th>MM 10</th>\n",
       "      <th>MM 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35035.984375</td>\n",
       "      <td>35035.984375</td>\n",
       "      <td>32883.781250</td>\n",
       "      <td>33572.117188</td>\n",
       "      <td>33572.117188</td>\n",
       "      <td>37838957079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.680171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33549.601562</td>\n",
       "      <td>33939.589844</td>\n",
       "      <td>32770.679688</td>\n",
       "      <td>33897.046875</td>\n",
       "      <td>33897.046875</td>\n",
       "      <td>38728974942</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>324.929688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33854.421875</td>\n",
       "      <td>34909.261719</td>\n",
       "      <td>33402.695312</td>\n",
       "      <td>34668.546875</td>\n",
       "      <td>34668.546875</td>\n",
       "      <td>24383958643</td>\n",
       "      <td>2.276009</td>\n",
       "      <td>771.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34665.566406</td>\n",
       "      <td>35937.566406</td>\n",
       "      <td>34396.476562</td>\n",
       "      <td>35287.781250</td>\n",
       "      <td>35287.781250</td>\n",
       "      <td>24924307911</td>\n",
       "      <td>1.786156</td>\n",
       "      <td>619.234375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35284.343750</td>\n",
       "      <td>35284.343750</td>\n",
       "      <td>33213.660156</td>\n",
       "      <td>33746.003906</td>\n",
       "      <td>33746.003906</td>\n",
       "      <td>26721554282</td>\n",
       "      <td>-4.369154</td>\n",
       "      <td>-1541.777344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34234.299219</td>\n",
       "      <td>...</td>\n",
       "      <td>722.677645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.742914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34234.299219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>63032.761719</td>\n",
       "      <td>63229.027344</td>\n",
       "      <td>59991.160156</td>\n",
       "      <td>60363.792969</td>\n",
       "      <td>60363.792969</td>\n",
       "      <td>34878965587</td>\n",
       "      <td>-4.244985</td>\n",
       "      <td>-2676.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61284.067187</td>\n",
       "      <td>...</td>\n",
       "      <td>1050.784231</td>\n",
       "      <td>1753.574395</td>\n",
       "      <td>2599.692717</td>\n",
       "      <td>-0.824298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61284.067187</td>\n",
       "      <td>62246.503125</td>\n",
       "      <td>61047.655990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>60352.000000</td>\n",
       "      <td>61435.183594</td>\n",
       "      <td>58208.187500</td>\n",
       "      <td>58482.386719</td>\n",
       "      <td>58482.386719</td>\n",
       "      <td>43657076893</td>\n",
       "      <td>-3.116779</td>\n",
       "      <td>-1881.406250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60842.091406</td>\n",
       "      <td>...</td>\n",
       "      <td>1653.712596</td>\n",
       "      <td>2119.235821</td>\n",
       "      <td>2325.862070</td>\n",
       "      <td>-0.579366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60842.091406</td>\n",
       "      <td>61939.380078</td>\n",
       "      <td>61210.411198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>58470.730469</td>\n",
       "      <td>62128.632812</td>\n",
       "      <td>58206.917969</td>\n",
       "      <td>60622.136719</td>\n",
       "      <td>60622.136719</td>\n",
       "      <td>45257083247</td>\n",
       "      <td>3.658794</td>\n",
       "      <td>2139.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60687.795312</td>\n",
       "      <td>...</td>\n",
       "      <td>1625.132637</td>\n",
       "      <td>2158.985166</td>\n",
       "      <td>2085.295552</td>\n",
       "      <td>0.548588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60687.795312</td>\n",
       "      <td>61798.985938</td>\n",
       "      <td>61425.147135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>60624.871094</td>\n",
       "      <td>62927.609375</td>\n",
       "      <td>60329.964844</td>\n",
       "      <td>62227.964844</td>\n",
       "      <td>62227.964844</td>\n",
       "      <td>36856881767</td>\n",
       "      <td>2.648914</td>\n",
       "      <td>1605.828125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60947.221094</td>\n",
       "      <td>...</td>\n",
       "      <td>1770.647418</td>\n",
       "      <td>1990.389379</td>\n",
       "      <td>1754.144410</td>\n",
       "      <td>0.617134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60947.221094</td>\n",
       "      <td>61595.583203</td>\n",
       "      <td>61752.243229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>62239.363281</td>\n",
       "      <td>62330.144531</td>\n",
       "      <td>60918.386719</td>\n",
       "      <td>61888.832031</td>\n",
       "      <td>61888.832031</td>\n",
       "      <td>32157938616</td>\n",
       "      <td>-0.544985</td>\n",
       "      <td>-339.132812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60717.022656</td>\n",
       "      <td>...</td>\n",
       "      <td>1481.844782</td>\n",
       "      <td>1278.920004</td>\n",
       "      <td>1753.896051</td>\n",
       "      <td>-0.248294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60717.022656</td>\n",
       "      <td>61185.182813</td>\n",
       "      <td>61771.902083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Id           Open          High           Low         Close     Adj Close  \\\n",
       "0    35035.984375  35035.984375  32883.781250  33572.117188  33572.117188   \n",
       "1    33549.601562  33939.589844  32770.679688  33897.046875  33897.046875   \n",
       "2    33854.421875  34909.261719  33402.695312  34668.546875  34668.546875   \n",
       "3    34665.566406  35937.566406  34396.476562  35287.781250  35287.781250   \n",
       "4    35284.343750  35284.343750  33213.660156  33746.003906  33746.003906   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "117  63032.761719  63229.027344  59991.160156  60363.792969  60363.792969   \n",
       "118  60352.000000  61435.183594  58208.187500  58482.386719  58482.386719   \n",
       "119  58470.730469  62128.632812  58206.917969  60622.136719  60622.136719   \n",
       "120  60624.871094  62927.609375  60329.964844  62227.964844  62227.964844   \n",
       "121  62239.363281  62330.144531  60918.386719  61888.832031  61888.832031   \n",
       "\n",
       "Id        Volume    Return    price dir  movement          sma5  ...  \\\n",
       "0    37838957079  0.000000     0.000000       1.0           NaN  ...   \n",
       "1    38728974942  0.967856   324.929688       1.0           NaN  ...   \n",
       "2    24383958643  2.276009   771.500000       1.0           NaN  ...   \n",
       "3    24924307911  1.786156   619.234375       0.0           NaN  ...   \n",
       "4    26721554282 -4.369154 -1541.777344       1.0  34234.299219  ...   \n",
       "..           ...       ...          ...       ...           ...  ...   \n",
       "117  34878965587 -4.244985 -2676.031250       0.0  61284.067187  ...   \n",
       "118  43657076893 -3.116779 -1881.406250       1.0  60842.091406  ...   \n",
       "119  45257083247  3.658794  2139.750000       1.0  60687.795312  ...   \n",
       "120  36856881767  2.648914  1605.828125       0.0  60947.221094  ...   \n",
       "121  32157938616 -0.544985  -339.132812       0.0  60717.022656  ...   \n",
       "\n",
       "Id         std 5       std 10       std 15      prop  move -1  move -2  \\\n",
       "0            NaN          NaN          NaN -0.680171      NaN      NaN   \n",
       "1            NaN          NaN          NaN  0.297239      1.0      NaN   \n",
       "2            NaN          NaN          NaN  0.540384      1.0      1.0   \n",
       "3            NaN          NaN          NaN  0.403750      1.0      1.0   \n",
       "4     722.677645          NaN          NaN -0.742914      0.0      1.0   \n",
       "..           ...          ...          ...       ...      ...      ...   \n",
       "117  1050.784231  1753.574395  2599.692717 -0.824298      0.0      1.0   \n",
       "118  1653.712596  2119.235821  2325.862070 -0.579366      0.0      0.0   \n",
       "119  1625.132637  2158.985166  2085.295552  0.548588      1.0      0.0   \n",
       "120  1770.647418  1990.389379  1754.144410  0.617134      1.0      1.0   \n",
       "121  1481.844782  1278.920004  1753.896051 -0.248294      0.0      1.0   \n",
       "\n",
       "Id   move -3          MM 5         MM 10         MM 15  \n",
       "0        NaN           NaN           NaN           NaN  \n",
       "1        NaN           NaN           NaN           NaN  \n",
       "2        NaN           NaN           NaN           NaN  \n",
       "3        1.0           NaN           NaN           NaN  \n",
       "4        1.0  34234.299219           NaN           NaN  \n",
       "..       ...           ...           ...           ...  \n",
       "117      0.0  61284.067187  62246.503125  61047.655990  \n",
       "118      1.0  60842.091406  61939.380078  61210.411198  \n",
       "119      0.0  60687.795312  61798.985938  61425.147135  \n",
       "120      0.0  60947.221094  61595.583203  61752.243229  \n",
       "121      1.0  60717.022656  61185.182813  61771.902083  \n",
       "\n",
       "[122 rows x 25 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc['std 5'] = btc['Close'].rolling(5).std()\n",
    "btc['std 10'] = btc['Close'].rolling(10).std()\n",
    "btc['std 15'] = btc['Close'].rolling(15).std()\n",
    "\n",
    "#propor√ß√£o candle em rela√ß√£o ao range do dia\n",
    "btc['prop'] = (btc['Close']-btc['Open'])/(btc['High']-btc['Low'])\n",
    "\n",
    "#movimento dias anteriores\n",
    "btc['move -1'] = btc['movement'].shift(1)\n",
    "btc['move -2'] = btc['movement'].shift(2)\n",
    "btc['move -3'] = btc['movement'].shift(3)\n",
    "\n",
    "#Media m√≥vel\n",
    "btc['MM 5'] = btc['Close'].rolling(5).mean()\n",
    "btc['MM 10'] = btc['Close'].rolling(10).mean()\n",
    "btc['MM 15'] = btc['Close'].rolling(15).mean()\n",
    "\n",
    "\n",
    "\n",
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9593ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id       Open      High       Low     Close  Adj Close    Volume    Return  \\\n",
      "0    0.144719  0.112175  0.102857  0.104041   0.104041  0.410386  0.528253   \n",
      "1    0.103666  0.081655  0.099555  0.113020   0.113020  0.429558  0.574471   \n",
      "2    0.112085  0.108647  0.118008  0.134341   0.134341  0.120545  0.636939   \n",
      "3    0.134488  0.137272  0.147024  0.151454   0.151454  0.132185  0.613547   \n",
      "4    0.151579  0.119088  0.112489  0.108846   0.108846  0.170901  0.319612   \n",
      "..        ...       ...       ...       ...        ...       ...       ...   \n",
      "117  0.917984  0.896967  0.894320  0.844439   0.844439  0.346623  0.325541   \n",
      "118  0.843942  0.847033  0.842262  0.792446   0.792446  0.535717  0.379417   \n",
      "119  0.791982  0.866336  0.842225  0.851579   0.851579  0.570183  0.702972   \n",
      "120  0.851478  0.888577  0.904212  0.895956   0.895956  0.389231  0.654747   \n",
      "121  0.896070  0.871946  0.921392  0.886584   0.886584  0.288009  0.502228   \n",
      "\n",
      "Id   price dir  movement      sma5  ...     std 5    std 10    std 15  \\\n",
      "0     0.573724       1.0       NaN  ...       NaN       NaN       NaN   \n",
      "1     0.605741       1.0       NaN  ...       NaN       NaN       NaN   \n",
      "2     0.649745       1.0       NaN  ...       NaN       NaN       NaN   \n",
      "3     0.634741       0.0       NaN  ...       NaN       NaN       NaN   \n",
      "4     0.421801       1.0  0.098308  ...  0.110385       NaN       NaN   \n",
      "..         ...       ...       ...  ...       ...       ...       ...   \n",
      "117   0.310035       0.0  0.940098  ...  0.222086  0.277653  0.373419   \n",
      "118   0.388335       1.0  0.926344  ...  0.427348  0.363730  0.314489   \n",
      "119   0.784568       1.0  0.921542  ...  0.417618  0.373088  0.262718   \n",
      "120   0.731957       0.0  0.929615  ...  0.467157  0.333400  0.191453   \n",
      "121   0.540306       0.0  0.922451  ...  0.368837  0.165918  0.191399   \n",
      "\n",
      "Id       prop  move -1  move -2  move -3      MM 5     MM 10     MM 15  \n",
      "0    0.133218      NaN      NaN      NaN       NaN       NaN       NaN  \n",
      "1    0.646002      1.0      NaN      NaN       NaN       NaN       NaN  \n",
      "2    0.773565      1.0      1.0      NaN       NaN       NaN       NaN  \n",
      "3    0.701882      1.0      1.0      1.0       NaN       NaN       NaN  \n",
      "4    0.100301      0.0      1.0      1.0  0.098308       NaN       NaN  \n",
      "..        ...      ...      ...      ...       ...       ...       ...  \n",
      "117  0.057604      0.0      1.0      0.0  0.940098  0.998273  0.975415  \n",
      "118  0.186104      0.0      0.0      1.0  0.926344  0.988232  0.980940  \n",
      "119  0.777869      1.0      0.0      0.0  0.921542  0.983643  0.988229  \n",
      "120  0.813830      1.0      1.0      0.0  0.929615  0.976993  0.999333  \n",
      "121  0.359796      0.0      1.0      1.0  0.922451  0.963576  1.000000  \n",
      "\n",
      "[122 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_min_max_scaled = btc.copy() \n",
    "for column in df_min_max_scaled.columns: \n",
    "    df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())     \n",
    "print(df_min_max_scaled)\n",
    "\n",
    "btc = df_min_max_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670ae60",
   "metadata": {},
   "source": [
    "## Juntando btc com twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aeb01895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc_tweets = data.join(btc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5a530e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>favorites mean</th>\n",
       "      <th>retweets mean</th>\n",
       "      <th>Compound mean</th>\n",
       "      <th>Positive mean</th>\n",
       "      <th>Negative mean</th>\n",
       "      <th>Neutral mean</th>\n",
       "      <th>Score Positive Retweet mean</th>\n",
       "      <th>Score Negative Retweet mean</th>\n",
       "      <th>Score Neutral Retweet mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std 5</th>\n",
       "      <th>std 10</th>\n",
       "      <th>std 15</th>\n",
       "      <th>prop</th>\n",
       "      <th>move -1</th>\n",
       "      <th>move -2</th>\n",
       "      <th>move -3</th>\n",
       "      <th>MM 5</th>\n",
       "      <th>MM 10</th>\n",
       "      <th>MM 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>176.307692</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.027462</td>\n",
       "      <td>0.031769</td>\n",
       "      <td>0.940769</td>\n",
       "      <td>0.131846</td>\n",
       "      <td>0.158846</td>\n",
       "      <td>196.017000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276116</td>\n",
       "      <td>0.697767</td>\n",
       "      <td>0.728178</td>\n",
       "      <td>0.223154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.298108</td>\n",
       "      <td>0.193020</td>\n",
       "      <td>0.107532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>404.103448</td>\n",
       "      <td>47.241379</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>0.978793</td>\n",
       "      <td>7.696828</td>\n",
       "      <td>30.319862</td>\n",
       "      <td>413.328138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.585153</td>\n",
       "      <td>0.727923</td>\n",
       "      <td>0.230263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.301643</td>\n",
       "      <td>0.218067</td>\n",
       "      <td>0.126636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>441.606061</td>\n",
       "      <td>52.909091</td>\n",
       "      <td>-0.039191</td>\n",
       "      <td>0.020788</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.950061</td>\n",
       "      <td>12.636242</td>\n",
       "      <td>21.415061</td>\n",
       "      <td>460.473182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295754</td>\n",
       "      <td>0.466272</td>\n",
       "      <td>0.706467</td>\n",
       "      <td>0.268858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296701</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.143394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>190.571429</td>\n",
       "      <td>24.607143</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>0.961607</td>\n",
       "      <td>6.666500</td>\n",
       "      <td>10.383500</td>\n",
       "      <td>198.125107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439269</td>\n",
       "      <td>0.337299</td>\n",
       "      <td>0.641680</td>\n",
       "      <td>0.216697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285153</td>\n",
       "      <td>0.249062</td>\n",
       "      <td>0.159994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>429.294118</td>\n",
       "      <td>61.411765</td>\n",
       "      <td>0.040906</td>\n",
       "      <td>0.025471</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>63.773412</td>\n",
       "      <td>0.236235</td>\n",
       "      <td>426.696235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295693</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>0.531892</td>\n",
       "      <td>0.830659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269667</td>\n",
       "      <td>0.263438</td>\n",
       "      <td>0.182489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>20.481481</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>0.933630</td>\n",
       "      <td>2.355926</td>\n",
       "      <td>1.938296</td>\n",
       "      <td>143.182852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193790</td>\n",
       "      <td>0.264478</td>\n",
       "      <td>0.406929</td>\n",
       "      <td>0.860696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>169.714286</td>\n",
       "      <td>21.452381</td>\n",
       "      <td>-0.031840</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.932667</td>\n",
       "      <td>22.493643</td>\n",
       "      <td>1.318071</td>\n",
       "      <td>167.355357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222086</td>\n",
       "      <td>0.277653</td>\n",
       "      <td>0.373419</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940098</td>\n",
       "      <td>0.998273</td>\n",
       "      <td>0.975415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>263.517241</td>\n",
       "      <td>33.068966</td>\n",
       "      <td>-0.036252</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.944034</td>\n",
       "      <td>1.644621</td>\n",
       "      <td>37.841379</td>\n",
       "      <td>257.118172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427348</td>\n",
       "      <td>0.363730</td>\n",
       "      <td>0.314489</td>\n",
       "      <td>0.186104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.988232</td>\n",
       "      <td>0.980940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>313.937500</td>\n",
       "      <td>46.312500</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>0.025354</td>\n",
       "      <td>0.943625</td>\n",
       "      <td>4.582375</td>\n",
       "      <td>0.537896</td>\n",
       "      <td>355.129729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.373088</td>\n",
       "      <td>0.262718</td>\n",
       "      <td>0.777869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921542</td>\n",
       "      <td>0.983643</td>\n",
       "      <td>0.988229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>220.381579</td>\n",
       "      <td>23.934211</td>\n",
       "      <td>-0.009863</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>0.956987</td>\n",
       "      <td>0.656987</td>\n",
       "      <td>1.042737</td>\n",
       "      <td>242.616092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467157</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.191453</td>\n",
       "      <td>0.813830</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929615</td>\n",
       "      <td>0.976993</td>\n",
       "      <td>0.999333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  favorites mean  retweets mean  Compound mean  Positive mean  \\\n",
       "30   2021-07-31      176.307692      20.000000       0.010946       0.027462   \n",
       "31   2021-08-01      404.103448      47.241379       0.001283       0.010069   \n",
       "32   2021-08-02      441.606061      52.909091      -0.039191       0.020788   \n",
       "33   2021-08-03      190.571429      24.607143       0.011696       0.019714   \n",
       "34   2021-08-04      429.294118      61.411765       0.040906       0.025471   \n",
       "..          ...             ...            ...            ...            ...   \n",
       "116  2021-10-25      127.000000      20.481481       0.064531       0.038833   \n",
       "117  2021-10-26      169.714286      21.452381      -0.031840       0.034548   \n",
       "118  2021-10-27      263.517241      33.068966      -0.036252       0.021552   \n",
       "119  2021-10-28      313.937500      46.312500       0.030342       0.031021   \n",
       "120  2021-10-29      220.381579      23.934211      -0.009863       0.020158   \n",
       "\n",
       "     Negative mean  Neutral mean  Score Positive Retweet mean  \\\n",
       "30        0.031769      0.940769                     0.131846   \n",
       "31        0.011138      0.978793                     7.696828   \n",
       "32        0.029212      0.950061                    12.636242   \n",
       "33        0.018643      0.961607                     6.666500   \n",
       "34        0.005353      0.969176                    63.773412   \n",
       "..             ...           ...                          ...   \n",
       "116       0.027481      0.933630                     2.355926   \n",
       "117       0.032833      0.932667                    22.493643   \n",
       "118       0.034483      0.944034                     1.644621   \n",
       "119       0.025354      0.943625                     4.582375   \n",
       "120       0.022868      0.956987                     0.656987   \n",
       "\n",
       "     Score Negative Retweet mean  Score Neutral Retweet mean  ...     std 5  \\\n",
       "30                      0.158846                  196.017000  ...  0.276116   \n",
       "31                     30.319862                  413.328138  ...  0.233083   \n",
       "32                     21.415061                  460.473182  ...  0.295754   \n",
       "33                     10.383500                  198.125107  ...  0.439269   \n",
       "34                      0.236235                  426.696235  ...  0.295693   \n",
       "..                           ...                         ...  ...       ...   \n",
       "116                     1.938296                  143.182852  ...  0.193790   \n",
       "117                     1.318071                  167.355357  ...  0.222086   \n",
       "118                    37.841379                  257.118172  ...  0.427348   \n",
       "119                     0.537896                  355.129729  ...  0.417618   \n",
       "120                     1.042737                  242.616092  ...  0.467157   \n",
       "\n",
       "       std 10    std 15      prop  move -1  move -2  move -3      MM 5  \\\n",
       "30   0.697767  0.728178  0.223154      0.0      1.0      1.0  0.298108   \n",
       "31   0.585153  0.727923  0.230263      0.0      0.0      1.0  0.301643   \n",
       "32   0.466272  0.706467  0.268858      0.0      0.0      0.0  0.296701   \n",
       "33   0.337299  0.641680  0.216697      0.0      0.0      0.0  0.285153   \n",
       "34   0.203823  0.531892  0.830659      1.0      0.0      0.0  0.269667   \n",
       "..        ...       ...       ...      ...      ...      ...       ...   \n",
       "116  0.264478  0.406929  0.860696      1.0      0.0      1.0  0.951590   \n",
       "117  0.277653  0.373419  0.057604      0.0      1.0      0.0  0.940098   \n",
       "118  0.363730  0.314489  0.186104      0.0      0.0      1.0  0.926344   \n",
       "119  0.373088  0.262718  0.777869      1.0      0.0      0.0  0.921542   \n",
       "120  0.333400  0.191453  0.813830      1.0      1.0      0.0  0.929615   \n",
       "\n",
       "        MM 10     MM 15  \n",
       "30   0.193020  0.107532  \n",
       "31   0.218067  0.126636  \n",
       "32   0.236441  0.143394  \n",
       "33   0.249062  0.159994  \n",
       "34   0.263438  0.182489  \n",
       "..        ...       ...  \n",
       "116  1.000000  0.968900  \n",
       "117  0.998273  0.975415  \n",
       "118  0.988232  0.980940  \n",
       "119  0.983643  0.988229  \n",
       "120  0.976993  0.999333  \n",
       "\n",
       "[91 rows x 35 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc_tweets\n",
    "\n",
    "df_btc_tweets = df_btc_tweets.drop([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,29], axis = 0)\n",
    "\n",
    "df_btc_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a48b18",
   "metadata": {},
   "source": [
    "## Criando regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d85a7f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 150)               4950      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               30000     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 200       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,150\n",
      "Trainable params: 35,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(Dense(150, input_dim=33, kernel_initializer='random_uniform',\n",
    "                    activation='sigmoid', use_bias=False))\n",
    "regressor.add(Dense(200, kernel_initializer='random_uniform', \n",
    "                    activation='sigmoid', use_bias=False))\n",
    "\n",
    "regressor.add(Dense(1, kernel_initializer='random_uniform',\n",
    "                    activation='linear', use_bias=False))\n",
    "\n",
    "regressor.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2453f",
   "metadata": {},
   "source": [
    "## Escalando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f47dcf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'favorites mean', 'retweets mean', 'Compound mean',\n",
       "       'Positive mean', 'Negative mean', 'Neutral mean',\n",
       "       'Score Positive Retweet mean', 'Score Negative Retweet mean',\n",
       "       'Score Neutral Retweet mean', 'Open', 'High', 'Low', 'Close',\n",
       "       'Adj Close', 'Volume', 'Return', 'price dir', 'movement', 'sma5',\n",
       "       'sma10', 'sma15', 'ema5', 'ema10', 'ema15', 'std 5', 'std 10', 'std 15',\n",
       "       'prop', 'move -1', 'move -2', 'move -3', 'MM 5', 'MM 10', 'MM 15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d921ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important_columns = [\"followers mean\", \"favorites mean\", \"retweets mean\", \"Compound mean\", \"Positive mean\", \"Negative mean\", \"Neutral mean\", 'Score Positive Retweet mean', 'Score Negative Retweet mean','Score Neutral Retweet mean','std 5','std 15','prop','move -1','move -2','MM 5','MM 10','sma10', 'ema5',]\n",
    "important_columns = ['date', 'favorites mean', 'retweets mean', 'Compound mean',\n",
    "       'Positive mean', 'Negative mean', 'Neutral mean',\n",
    "       'Score Positive Retweet mean', 'Score Negative Retweet mean',\n",
    "       'Score Neutral Retweet mean', 'Open', 'High', 'Low', 'Close',\n",
    "       'Adj Close', 'Volume', 'Return', 'price dir', 'sma5',\n",
    "       'sma10', 'sma15', 'ema5', 'ema10', 'ema15', 'std 5', 'std 10', 'std 15',\n",
    "       'prop', 'move -1', 'move -2', 'move -3', 'MM 5', 'MM 10', 'MM 15']\n",
    "\n",
    "x = df_btc_tweets[important_columns]\n",
    "y = df_btc_tweets[[\"movement\"]]\n",
    "y = y.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70b2c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imblearn\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# usar t√©cnica under-sampling\n",
    "rus = RandomOverSampler()\n",
    "x_res, y_res = rus.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629f191",
   "metadata": {},
   "source": [
    "### Prox passo, descobrir como associar com exemplo \"Loading the numerical and categorical data\" do site https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d72fa587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 35)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba2eb621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'favorites mean',\n",
       " 'retweets mean',\n",
       " 'Compound mean',\n",
       " 'Positive mean',\n",
       " 'Negative mean',\n",
       " 'Neutral mean',\n",
       " 'Score Positive Retweet mean',\n",
       " 'Score Negative Retweet mean',\n",
       " 'Score Neutral Retweet mean',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close',\n",
       " 'Volume',\n",
       " 'Return',\n",
       " 'price dir',\n",
       " 'movement',\n",
       " 'sma5',\n",
       " 'sma10',\n",
       " 'sma15',\n",
       " 'ema5',\n",
       " 'ema10',\n",
       " 'ema15',\n",
       " 'std 5',\n",
       " 'std 10',\n",
       " 'std 15',\n",
       " 'prop',\n",
       " 'move -1',\n",
       " 'move -2',\n",
       " 'move -3',\n",
       " 'MM 5',\n",
       " 'MM 10',\n",
       " 'MM 15']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df_btc_tweets.columns.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_columns = ['favorites mean',\n",
    " 'favorites count',\n",
    " 'retweets mean',\n",
    " 'retweets count',\n",
    " 'Compound mean',\n",
    " 'Compound count',\n",
    " 'Positive mean',\n",
    " 'Positive count',\n",
    " 'Negative mean',\n",
    " 'Negative count',\n",
    " 'Neutral mean',\n",
    " 'Neutral count']\n",
    "\n",
    "\n",
    "x = df_btc_tweets[important_columns]\n",
    "y = df_btc_tweets[['movement']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f56e4157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['favorites mean',\n",
       " 'retweets mean',\n",
       " 'Compound mean',\n",
       " 'Positive mean',\n",
       " 'Negative mean',\n",
       " 'Neutral mean',\n",
       " 'Score Positive Retweet mean',\n",
       " 'Score Negative Retweet mean',\n",
       " 'Score Neutral Retweet mean',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close',\n",
       " 'Volume',\n",
       " 'Return',\n",
       " 'price dir',\n",
       " 'sma5',\n",
       " 'sma10',\n",
       " 'sma15',\n",
       " 'ema5',\n",
       " 'ema10',\n",
       " 'ema15',\n",
       " 'std 5',\n",
       " 'std 10',\n",
       " 'std 15',\n",
       " 'prop',\n",
       " 'move -1',\n",
       " 'move -2',\n",
       " 'move -3',\n",
       " 'MM 5',\n",
       " 'MM 10',\n",
       " 'MM 15']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train.columns.tolist()\n",
    "x_train = x[:85]\n",
    "y_train = y[:85]\n",
    "x_test = x[85:]\n",
    "y_test = y[85:]\n",
    "\n",
    "x_train.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "x_test.drop(['date'], axis=1, inplace=True)\n",
    "#x_train = np.asarray(x_train).astype(np.float32)\n",
    "#y_train = np.asarray(y_train).astype(np.float32)\n",
    "\n",
    "\n",
    "x_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc8675da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7777 - val_loss: 0.4687\n",
      "Epoch 2/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5136 - val_loss: 0.3135\n",
      "Epoch 3/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3415 - val_loss: 0.2484\n",
      "Epoch 4/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2583 - val_loss: 0.2590\n",
      "Epoch 5/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2509 - val_loss: 0.3133\n",
      "Epoch 6/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2897 - val_loss: 0.3686\n",
      "Epoch 7/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3347 - val_loss: 0.3975\n",
      "Epoch 8/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3588 - val_loss: 0.3954\n",
      "Epoch 9/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3565 - val_loss: 0.3702\n",
      "Epoch 10/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3351 - val_loss: 0.3340\n",
      "Epoch 11/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3052 - val_loss: 0.2975\n",
      "Epoch 12/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2766 - val_loss: 0.2685\n",
      "Epoch 13/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2560 - val_loss: 0.2506\n",
      "Epoch 14/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2463 - val_loss: 0.2438\n",
      "Epoch 15/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2467 - val_loss: 0.2452\n",
      "Epoch 16/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2541 - val_loss: 0.2505\n",
      "Epoch 17/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2640 - val_loss: 0.2557\n",
      "Epoch 18/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2723 - val_loss: 0.2584\n",
      "Epoch 19/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2765 - val_loss: 0.2576\n",
      "Epoch 20/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2757 - val_loss: 0.2539\n",
      "Epoch 21/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2707 - val_loss: 0.2490\n",
      "Epoch 22/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2632 - val_loss: 0.2447\n",
      "Epoch 23/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2553 - val_loss: 0.2427\n",
      "Epoch 24/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2489 - val_loss: 0.2437\n",
      "Epoch 25/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2452 - val_loss: 0.2477\n",
      "Epoch 26/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2444 - val_loss: 0.2538\n",
      "Epoch 27/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2461 - val_loss: 0.2603\n",
      "Epoch 28/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2491 - val_loss: 0.2658\n",
      "Epoch 29/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2519 - val_loss: 0.2689\n",
      "Epoch 30/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2537 - val_loss: 0.2691\n",
      "Epoch 31/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2537 - val_loss: 0.2664\n",
      "Epoch 32/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2522 - val_loss: 0.2617\n",
      "Epoch 33/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2496 - val_loss: 0.2560\n",
      "Epoch 34/1024\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2468 - val_loss: 0.2502\n",
      "Epoch 35/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2446 - val_loss: 0.2453\n",
      "Epoch 36/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2433 - val_loss: 0.2416\n",
      "Epoch 37/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2432 - val_loss: 0.2392\n",
      "Epoch 38/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2439 - val_loss: 0.2379\n",
      "Epoch 39/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2450 - val_loss: 0.2373\n",
      "Epoch 40/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2459 - val_loss: 0.2368\n",
      "Epoch 41/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2462 - val_loss: 0.2365\n",
      "Epoch 42/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2458 - val_loss: 0.2363\n",
      "Epoch 43/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2449 - val_loss: 0.2365\n",
      "Epoch 44/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2437 - val_loss: 0.2374\n",
      "Epoch 45/1024\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2427 - val_loss: 0.2390\n",
      "Epoch 46/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2420 - val_loss: 0.2409\n",
      "Epoch 47/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2418 - val_loss: 0.2428\n",
      "Epoch 48/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2420 - val_loss: 0.2443\n",
      "Epoch 49/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2423 - val_loss: 0.2450\n",
      "Epoch 50/1024\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2424 - val_loss: 0.2445\n",
      "Epoch 51/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2423 - val_loss: 0.2431\n",
      "Epoch 52/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2419 - val_loss: 0.2410\n",
      "Epoch 53/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2413 - val_loss: 0.2389\n",
      "Epoch 54/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2408 - val_loss: 0.2372\n",
      "Epoch 55/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2406 - val_loss: 0.2358\n",
      "Epoch 56/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2405 - val_loss: 0.2348\n",
      "Epoch 57/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2406 - val_loss: 0.2340\n",
      "Epoch 58/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2407 - val_loss: 0.2333\n",
      "Epoch 59/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2406 - val_loss: 0.2325\n",
      "Epoch 60/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2402 - val_loss: 0.2319\n",
      "Epoch 61/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2398 - val_loss: 0.2318\n",
      "Epoch 62/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2394 - val_loss: 0.2321\n",
      "Epoch 63/1024\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2392 - val_loss: 0.2326\n",
      "Epoch 64/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2392 - val_loss: 0.2330\n",
      "Epoch 65/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2391 - val_loss: 0.2329\n",
      "Epoch 66/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2390 - val_loss: 0.2326\n",
      "Epoch 67/1024\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2389 - val_loss: 0.2321\n",
      "Epoch 68/1024\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2387 - val_loss: 0.2312\n",
      "Epoch 69/1024\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.2385 - val_loss: 0.2302\n",
      "Epoch 70/1024\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2383 - val_loss: 0.2291\n",
      "Epoch 71/1024\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2382 - val_loss: 0.2280\n",
      "Epoch 72/1024\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2380 - val_loss: 0.2271\n",
      "Epoch 73/1024\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2377 - val_loss: 0.2266\n",
      "Epoch 74/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2376 - val_loss: 0.2263\n",
      "Epoch 75/1024\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2374 - val_loss: 0.2262\n",
      "Epoch 76/1024\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2373 - val_loss: 0.2261\n",
      "Epoch 77/1024\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2371 - val_loss: 0.2258\n",
      "Epoch 78/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2370 - val_loss: 0.2255\n",
      "Epoch 79/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2368 - val_loss: 0.2249\n",
      "Epoch 80/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2366 - val_loss: 0.2242\n",
      "Epoch 81/1024\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2364 - val_loss: 0.2234\n",
      "Epoch 82/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2362 - val_loss: 0.2227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2360 - val_loss: 0.2222\n",
      "Epoch 84/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2358 - val_loss: 0.2219\n",
      "Epoch 85/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2357 - val_loss: 0.2217\n",
      "Epoch 86/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2355 - val_loss: 0.2214\n",
      "Epoch 87/1024\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2354 - val_loss: 0.2211\n",
      "Epoch 88/1024\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2352 - val_loss: 0.2207\n",
      "Epoch 89/1024\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2350 - val_loss: 0.2201\n",
      "Epoch 90/1024\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2348 - val_loss: 0.2195\n",
      "Epoch 91/1024\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2347 - val_loss: 0.2188\n",
      "Epoch 92/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2345 - val_loss: 0.2181\n",
      "Epoch 93/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2343 - val_loss: 0.2175\n",
      "Epoch 94/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2342 - val_loss: 0.2169\n",
      "Epoch 95/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2340 - val_loss: 0.2164\n",
      "Epoch 96/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2338 - val_loss: 0.2161\n",
      "Epoch 97/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2336 - val_loss: 0.2157\n",
      "Epoch 98/1024\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2334 - val_loss: 0.2154\n",
      "Epoch 99/1024\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2333 - val_loss: 0.2151\n",
      "Epoch 100/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2331 - val_loss: 0.2146\n",
      "Epoch 101/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2329 - val_loss: 0.2140\n",
      "Epoch 102/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2327 - val_loss: 0.2134\n",
      "Epoch 103/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2325 - val_loss: 0.2127\n",
      "Epoch 104/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2324 - val_loss: 0.2122\n",
      "Epoch 105/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2322 - val_loss: 0.2116\n",
      "Epoch 106/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2320 - val_loss: 0.2112\n",
      "Epoch 107/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2318 - val_loss: 0.2108\n",
      "Epoch 108/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2316 - val_loss: 0.2104\n",
      "Epoch 109/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2315 - val_loss: 0.2100\n",
      "Epoch 110/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2313 - val_loss: 0.2096\n",
      "Epoch 111/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2311 - val_loss: 0.2091\n",
      "Epoch 112/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2309 - val_loss: 0.2086\n",
      "Epoch 113/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2307 - val_loss: 0.2082\n",
      "Epoch 114/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2305 - val_loss: 0.2077\n",
      "Epoch 115/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2304 - val_loss: 0.2073\n",
      "Epoch 116/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2302 - val_loss: 0.2069\n",
      "Epoch 117/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2300 - val_loss: 0.2065\n",
      "Epoch 118/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2298 - val_loss: 0.2061\n",
      "Epoch 119/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2296 - val_loss: 0.2056\n",
      "Epoch 120/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2294 - val_loss: 0.2052\n",
      "Epoch 121/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2292 - val_loss: 0.2048\n",
      "Epoch 122/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2291 - val_loss: 0.2043\n",
      "Epoch 123/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2289 - val_loss: 0.2039\n",
      "Epoch 124/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2287 - val_loss: 0.2035\n",
      "Epoch 125/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2285 - val_loss: 0.2031\n",
      "Epoch 126/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2283 - val_loss: 0.2027\n",
      "Epoch 127/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2281 - val_loss: 0.2023\n",
      "Epoch 128/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2279 - val_loss: 0.2018\n",
      "Epoch 129/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2277 - val_loss: 0.2014\n",
      "Epoch 130/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2275 - val_loss: 0.2010\n",
      "Epoch 131/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2273 - val_loss: 0.2007\n",
      "Epoch 132/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2271 - val_loss: 0.2003\n",
      "Epoch 133/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2269 - val_loss: 0.1999\n",
      "Epoch 134/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2267 - val_loss: 0.1995\n",
      "Epoch 135/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2265 - val_loss: 0.1991\n",
      "Epoch 136/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2263 - val_loss: 0.1988\n",
      "Epoch 137/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2261 - val_loss: 0.1984\n",
      "Epoch 138/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2259 - val_loss: 0.1981\n",
      "Epoch 139/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2257 - val_loss: 0.1977\n",
      "Epoch 140/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2255 - val_loss: 0.1973\n",
      "Epoch 141/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2253 - val_loss: 0.1969\n",
      "Epoch 142/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2251 - val_loss: 0.1965\n",
      "Epoch 143/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2249 - val_loss: 0.1961\n",
      "Epoch 144/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2247 - val_loss: 0.1957\n",
      "Epoch 145/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2245 - val_loss: 0.1953\n",
      "Epoch 146/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2242 - val_loss: 0.1950\n",
      "Epoch 147/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2240 - val_loss: 0.1946\n",
      "Epoch 148/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2238 - val_loss: 0.1942\n",
      "Epoch 149/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2236 - val_loss: 0.1938\n",
      "Epoch 150/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2234 - val_loss: 0.1934\n",
      "Epoch 151/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2231 - val_loss: 0.1930\n",
      "Epoch 152/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2229 - val_loss: 0.1926\n",
      "Epoch 153/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2227 - val_loss: 0.1923\n",
      "Epoch 154/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2224 - val_loss: 0.1919\n",
      "Epoch 155/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2222 - val_loss: 0.1915\n",
      "Epoch 156/1024\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2219 - val_loss: 0.1912\n",
      "Epoch 157/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2217 - val_loss: 0.1908\n",
      "Epoch 158/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2214 - val_loss: 0.1904\n",
      "Epoch 159/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2212 - val_loss: 0.1901\n",
      "Epoch 160/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2209 - val_loss: 0.1897\n",
      "Epoch 161/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2207 - val_loss: 0.1893\n",
      "Epoch 162/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2205 - val_loss: 0.1890\n",
      "Epoch 163/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2202 - val_loss: 0.1886\n",
      "Epoch 164/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2200 - val_loss: 0.1883\n",
      "Epoch 165/1024\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2197 - val_loss: 0.1879\n",
      "Epoch 166/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2194 - val_loss: 0.1876\n",
      "Epoch 167/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2192 - val_loss: 0.1873\n",
      "Epoch 168/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2189 - val_loss: 0.1870\n",
      "Epoch 169/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2186 - val_loss: 0.1867\n",
      "Epoch 170/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2184 - val_loss: 0.1864\n",
      "Epoch 171/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2181 - val_loss: 0.1861\n",
      "Epoch 172/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2178 - val_loss: 0.1858\n",
      "Epoch 173/1024\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2175 - val_loss: 0.1855\n",
      "Epoch 174/1024\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2173 - val_loss: 0.1852\n",
      "Epoch 175/1024\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2170 - val_loss: 0.1848\n",
      "Epoch 176/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2167 - val_loss: 0.1844\n",
      "Epoch 177/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2164 - val_loss: 0.1840\n",
      "Epoch 178/1024\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2161 - val_loss: 0.1836\n",
      "Epoch 179/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2158 - val_loss: 0.1832\n",
      "Epoch 180/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2155 - val_loss: 0.1828\n",
      "Epoch 181/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2152 - val_loss: 0.1824\n",
      "Epoch 182/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2149 - val_loss: 0.1820\n",
      "Epoch 183/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2146 - val_loss: 0.1816\n",
      "Epoch 184/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2143 - val_loss: 0.1812\n",
      "Epoch 185/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2140 - val_loss: 0.1808\n",
      "Epoch 186/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2137 - val_loss: 0.1804\n",
      "Epoch 187/1024\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2134 - val_loss: 0.1800\n",
      "Epoch 188/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2131 - val_loss: 0.1796\n",
      "Epoch 189/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2128 - val_loss: 0.1792\n",
      "Epoch 190/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2125 - val_loss: 0.1787\n",
      "Epoch 191/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2121 - val_loss: 0.1783\n",
      "Epoch 192/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2118 - val_loss: 0.1779\n",
      "Epoch 193/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2115 - val_loss: 0.1775\n",
      "Epoch 194/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2111 - val_loss: 0.1771\n",
      "Epoch 195/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2108 - val_loss: 0.1767\n",
      "Epoch 196/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2105 - val_loss: 0.1763\n",
      "Epoch 197/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2101 - val_loss: 0.1759\n",
      "Epoch 198/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2098 - val_loss: 0.1755\n",
      "Epoch 199/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2094 - val_loss: 0.1751\n",
      "Epoch 200/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2091 - val_loss: 0.1748\n",
      "Epoch 201/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2087 - val_loss: 0.1744\n",
      "Epoch 202/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2084 - val_loss: 0.1740\n",
      "Epoch 203/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2080 - val_loss: 0.1736\n",
      "Epoch 204/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2077 - val_loss: 0.1732\n",
      "Epoch 205/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2073 - val_loss: 0.1728\n",
      "Epoch 206/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2069 - val_loss: 0.1724\n",
      "Epoch 207/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2066 - val_loss: 0.1720\n",
      "Epoch 208/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2062 - val_loss: 0.1715\n",
      "Epoch 209/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2058 - val_loss: 0.1711\n",
      "Epoch 210/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2054 - val_loss: 0.1706\n",
      "Epoch 211/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2051 - val_loss: 0.1701\n",
      "Epoch 212/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2047 - val_loss: 0.1696\n",
      "Epoch 213/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2043 - val_loss: 0.1690\n",
      "Epoch 214/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2039 - val_loss: 0.1685\n",
      "Epoch 215/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2035 - val_loss: 0.1679\n",
      "Epoch 216/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2031 - val_loss: 0.1673\n",
      "Epoch 217/1024\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2027 - val_loss: 0.1667\n",
      "Epoch 218/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2023 - val_loss: 0.1661\n",
      "Epoch 219/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2019 - val_loss: 0.1655\n",
      "Epoch 220/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2015 - val_loss: 0.1649\n",
      "Epoch 221/1024\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2011 - val_loss: 0.1644\n",
      "Epoch 222/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2007 - val_loss: 0.1638\n",
      "Epoch 223/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2003 - val_loss: 0.1632\n",
      "Epoch 224/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1999 - val_loss: 0.1626\n",
      "Epoch 225/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1995 - val_loss: 0.1620\n",
      "Epoch 226/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1990 - val_loss: 0.1614\n",
      "Epoch 227/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1986 - val_loss: 0.1608\n",
      "Epoch 228/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1982 - val_loss: 0.1602\n",
      "Epoch 229/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1978 - val_loss: 0.1596\n",
      "Epoch 230/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1974 - val_loss: 0.1591\n",
      "Epoch 231/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1969 - val_loss: 0.1585\n",
      "Epoch 232/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1965 - val_loss: 0.1580\n",
      "Epoch 233/1024\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1961 - val_loss: 0.1574\n",
      "Epoch 234/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1956 - val_loss: 0.1569\n",
      "Epoch 235/1024\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1952 - val_loss: 0.1563\n",
      "Epoch 236/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1948 - val_loss: 0.1557\n",
      "Epoch 237/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1943 - val_loss: 0.1552\n",
      "Epoch 238/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1939 - val_loss: 0.1546\n",
      "Epoch 239/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1934 - val_loss: 0.1541\n",
      "Epoch 240/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1930 - val_loss: 0.1536\n",
      "Epoch 241/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1925 - val_loss: 0.1530\n",
      "Epoch 242/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1921 - val_loss: 0.1525\n",
      "Epoch 243/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1916 - val_loss: 0.1519\n",
      "Epoch 244/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1911 - val_loss: 0.1513\n",
      "Epoch 245/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1907 - val_loss: 0.1507\n",
      "Epoch 246/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1902 - val_loss: 0.1501\n",
      "Epoch 247/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1897 - val_loss: 0.1495\n",
      "Epoch 248/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1893 - val_loss: 0.1488\n",
      "Epoch 249/1024\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1888 - val_loss: 0.1482\n",
      "Epoch 250/1024\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1883 - val_loss: 0.1475\n",
      "Epoch 251/1024\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1878 - val_loss: 0.1469\n",
      "Epoch 252/1024\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1873 - val_loss: 0.1463\n",
      "Epoch 253/1024\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1869 - val_loss: 0.1457\n",
      "Epoch 254/1024\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1864 - val_loss: 0.1451\n",
      "Epoch 255/1024\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1859 - val_loss: 0.1445\n",
      "Epoch 256/1024\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1854 - val_loss: 0.1439\n",
      "Epoch 257/1024\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1849 - val_loss: 0.1433\n",
      "Epoch 258/1024\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1845 - val_loss: 0.1426\n",
      "Epoch 259/1024\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1840 - val_loss: 0.1419\n",
      "Epoch 260/1024\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1835 - val_loss: 0.1413\n",
      "Epoch 261/1024\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1830 - val_loss: 0.1407\n",
      "Epoch 262/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1825 - val_loss: 0.1401\n",
      "Epoch 263/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1820 - val_loss: 0.1395\n",
      "Epoch 264/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1815 - val_loss: 0.1390\n",
      "Epoch 265/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1810 - val_loss: 0.1381\n",
      "Epoch 266/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1806 - val_loss: 0.1378\n",
      "Epoch 267/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1801 - val_loss: 0.1368\n",
      "Epoch 268/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1796 - val_loss: 0.1364\n",
      "Epoch 269/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1791 - val_loss: 0.1358\n",
      "Epoch 270/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1786 - val_loss: 0.1351\n",
      "Epoch 271/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1781 - val_loss: 0.1345\n",
      "Epoch 272/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1776 - val_loss: 0.1337\n",
      "Epoch 273/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1771 - val_loss: 0.1332\n",
      "Epoch 274/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1766 - val_loss: 0.1324\n",
      "Epoch 275/1024\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1761 - val_loss: 0.1317\n",
      "Epoch 276/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1756 - val_loss: 0.1312\n",
      "Epoch 277/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1751 - val_loss: 0.1303\n",
      "Epoch 278/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1746 - val_loss: 0.1297\n",
      "Epoch 279/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1741 - val_loss: 0.1289\n",
      "Epoch 280/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1736 - val_loss: 0.1283\n",
      "Epoch 281/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1731 - val_loss: 0.1276\n",
      "Epoch 282/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1726 - val_loss: 0.1268\n",
      "Epoch 283/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1721 - val_loss: 0.1263\n",
      "Epoch 284/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1716 - val_loss: 0.1255\n",
      "Epoch 285/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1711 - val_loss: 0.1248\n",
      "Epoch 286/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1706 - val_loss: 0.1240\n",
      "Epoch 287/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1701 - val_loss: 0.1234\n",
      "Epoch 288/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1696 - val_loss: 0.1227\n",
      "Epoch 289/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1691 - val_loss: 0.1218\n",
      "Epoch 290/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1686 - val_loss: 0.1211\n",
      "Epoch 291/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1681 - val_loss: 0.1203\n",
      "Epoch 292/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1676 - val_loss: 0.1197\n",
      "Epoch 293/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1671 - val_loss: 0.1187\n",
      "Epoch 294/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1666 - val_loss: 0.1183\n",
      "Epoch 295/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1662 - val_loss: 0.1172\n",
      "Epoch 296/1024\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1657 - val_loss: 0.1169\n",
      "Epoch 297/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1652 - val_loss: 0.1156\n",
      "Epoch 298/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1647 - val_loss: 0.1152\n",
      "Epoch 299/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1642 - val_loss: 0.1140\n",
      "Epoch 300/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1637 - val_loss: 0.1133\n",
      "Epoch 301/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1632 - val_loss: 0.1125\n",
      "Epoch 302/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1627 - val_loss: 0.1114\n",
      "Epoch 303/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1622 - val_loss: 0.1109\n",
      "Epoch 304/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1618 - val_loss: 0.1096\n",
      "Epoch 305/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1613 - val_loss: 0.1089\n",
      "Epoch 306/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1608 - val_loss: 0.1079\n",
      "Epoch 307/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1603 - val_loss: 0.1068\n",
      "Epoch 308/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1598 - val_loss: 0.1062\n",
      "Epoch 309/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1593 - val_loss: 0.1049\n",
      "Epoch 310/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1589 - val_loss: 0.1042\n",
      "Epoch 311/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1584 - val_loss: 0.1031\n",
      "Epoch 312/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1579 - val_loss: 0.1022\n",
      "Epoch 313/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1574 - val_loss: 0.1013\n",
      "Epoch 314/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1569 - val_loss: 0.1002\n",
      "Epoch 315/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1565 - val_loss: 0.0993\n",
      "Epoch 316/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1560 - val_loss: 0.0982\n",
      "Epoch 317/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1555 - val_loss: 0.0973\n",
      "Epoch 318/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1551 - val_loss: 0.0962\n",
      "Epoch 319/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1546 - val_loss: 0.0953\n",
      "Epoch 320/1024\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1541 - val_loss: 0.0943\n",
      "Epoch 321/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1536 - val_loss: 0.0933\n",
      "Epoch 322/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1532 - val_loss: 0.0923\n",
      "Epoch 323/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1527 - val_loss: 0.0913\n",
      "Epoch 324/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1522 - val_loss: 0.0903\n",
      "Epoch 325/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1518 - val_loss: 0.0894\n",
      "Epoch 326/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1513 - val_loss: 0.0884\n",
      "Epoch 327/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1509 - val_loss: 0.0876\n",
      "Epoch 328/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1504 - val_loss: 0.0865\n",
      "Epoch 329/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1500 - val_loss: 0.0861\n",
      "Epoch 330/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1496 - val_loss: 0.0847\n",
      "Epoch 331/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1492 - val_loss: 0.0854\n",
      "Epoch 332/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1489 - val_loss: 0.0829\n",
      "Epoch 333/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1485 - val_loss: 0.0838\n",
      "Epoch 334/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1479 - val_loss: 0.0817\n",
      "Epoch 335/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1473 - val_loss: 0.0807\n",
      "Epoch 336/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1469 - val_loss: 0.0820\n",
      "Epoch 337/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1466 - val_loss: 0.0789\n",
      "Epoch 338/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1462 - val_loss: 0.0793\n",
      "Epoch 339/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1456 - val_loss: 0.0790\n",
      "Epoch 340/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1452 - val_loss: 0.0770\n",
      "Epoch 341/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1449 - val_loss: 0.0786\n",
      "Epoch 342/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1444 - val_loss: 0.0766\n",
      "Epoch 343/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1439 - val_loss: 0.0758\n",
      "Epoch 344/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1435 - val_loss: 0.0772\n",
      "Epoch 345/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1431 - val_loss: 0.0746\n",
      "Epoch 346/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1427 - val_loss: 0.0753\n",
      "Epoch 347/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1422 - val_loss: 0.0752\n",
      "Epoch 348/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1417 - val_loss: 0.0734\n",
      "Epoch 349/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1414 - val_loss: 0.0749\n",
      "Epoch 350/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1409 - val_loss: 0.0730\n",
      "Epoch 351/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1404 - val_loss: 0.0728\n",
      "Epoch 352/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1400 - val_loss: 0.0733\n",
      "Epoch 353/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1395 - val_loss: 0.0713\n",
      "Epoch 354/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1391 - val_loss: 0.0726\n",
      "Epoch 355/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1387 - val_loss: 0.0710\n",
      "Epoch 356/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1382 - val_loss: 0.0719\n",
      "Epoch 357/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1377 - val_loss: 0.0719\n",
      "Epoch 358/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1373 - val_loss: 0.0709\n",
      "Epoch 359/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1368 - val_loss: 0.0718\n",
      "Epoch 360/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1364 - val_loss: 0.0697\n",
      "Epoch 361/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1360 - val_loss: 0.0709\n",
      "Epoch 362/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1355 - val_loss: 0.0690\n",
      "Epoch 363/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1351 - val_loss: 0.0700\n",
      "Epoch 364/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1347 - val_loss: 0.0687\n",
      "Epoch 365/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1342 - val_loss: 0.0687\n",
      "Epoch 366/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1338 - val_loss: 0.0682\n",
      "Epoch 367/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1334 - val_loss: 0.0675\n",
      "Epoch 368/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1330 - val_loss: 0.0682\n",
      "Epoch 369/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1326 - val_loss: 0.0669\n",
      "Epoch 370/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1322 - val_loss: 0.0685\n",
      "Epoch 371/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1318 - val_loss: 0.0660\n",
      "Epoch 372/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1315 - val_loss: 0.0691\n",
      "Epoch 373/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1312 - val_loss: 0.0649\n",
      "Epoch 374/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1309 - val_loss: 0.0701\n",
      "Epoch 375/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1307 - val_loss: 0.0642\n",
      "Epoch 376/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1303 - val_loss: 0.0683\n",
      "Epoch 377/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1296 - val_loss: 0.0653\n",
      "Epoch 378/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1290 - val_loss: 0.0647\n",
      "Epoch 379/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1287 - val_loss: 0.0677\n",
      "Epoch 380/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1285 - val_loss: 0.0631\n",
      "Epoch 381/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1283 - val_loss: 0.0666\n",
      "Epoch 382/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1277 - val_loss: 0.0638\n",
      "Epoch 383/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1272 - val_loss: 0.0637\n",
      "Epoch 384/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1268 - val_loss: 0.0662\n",
      "Epoch 385/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1266 - val_loss: 0.0627\n",
      "Epoch 386/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1263 - val_loss: 0.0658\n",
      "Epoch 387/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1259 - val_loss: 0.0630\n",
      "Epoch 388/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1254 - val_loss: 0.0631\n",
      "Epoch 389/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1250 - val_loss: 0.0645\n",
      "Epoch 390/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1248 - val_loss: 0.0618\n",
      "Epoch 391/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1245 - val_loss: 0.0647\n",
      "Epoch 392/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1242 - val_loss: 0.0616\n",
      "Epoch 393/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1238 - val_loss: 0.0630\n",
      "Epoch 394/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1233 - val_loss: 0.0625\n",
      "Epoch 395/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1230 - val_loss: 0.0615\n",
      "Epoch 396/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1227 - val_loss: 0.0635\n",
      "Epoch 397/1024\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1224 - val_loss: 0.0608\n",
      "Epoch 398/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1221 - val_loss: 0.0638\n",
      "Epoch 399/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1218 - val_loss: 0.0602\n",
      "Epoch 400/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1214 - val_loss: 0.0633\n",
      "Epoch 401/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1211 - val_loss: 0.0598\n",
      "Epoch 402/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1208 - val_loss: 0.0624\n",
      "Epoch 403/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1204 - val_loss: 0.0595\n",
      "Epoch 404/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1200 - val_loss: 0.0615\n",
      "Epoch 405/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1197 - val_loss: 0.0596\n",
      "Epoch 406/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1193 - val_loss: 0.0608\n",
      "Epoch 407/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1190 - val_loss: 0.0598\n",
      "Epoch 408/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1186 - val_loss: 0.0602\n",
      "Epoch 409/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1183 - val_loss: 0.0596\n",
      "Epoch 410/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1180 - val_loss: 0.0597\n",
      "Epoch 411/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1176 - val_loss: 0.0595\n",
      "Epoch 412/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1173 - val_loss: 0.0596\n",
      "Epoch 413/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1170 - val_loss: 0.0593\n",
      "Epoch 414/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1167 - val_loss: 0.0593\n",
      "Epoch 415/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1163 - val_loss: 0.0587\n",
      "Epoch 416/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1160 - val_loss: 0.0591\n",
      "Epoch 417/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1157 - val_loss: 0.0577\n",
      "Epoch 418/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1154 - val_loss: 0.0601\n",
      "Epoch 419/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1152 - val_loss: 0.0559\n",
      "Epoch 420/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1153 - val_loss: 0.0671\n",
      "Epoch 421/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1165 - val_loss: 0.0556\n",
      "Epoch 422/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1195 - val_loss: 0.0749\n",
      "Epoch 423/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1190 - val_loss: 0.0553\n",
      "Epoch 424/1024\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1139 - val_loss: 0.0540\n",
      "Epoch 425/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1155 - val_loss: 0.0702\n",
      "Epoch 426/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1164 - val_loss: 0.0568\n",
      "Epoch 427/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1128 - val_loss: 0.0540\n",
      "Epoch 428/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1148 - val_loss: 0.0650\n",
      "Epoch 429/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1138 - val_loss: 0.0597\n",
      "Epoch 430/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1122 - val_loss: 0.0529\n",
      "Epoch 431/1024\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1138 - val_loss: 0.0591\n",
      "Epoch 432/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1117 - val_loss: 0.0628\n",
      "Epoch 433/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1123 - val_loss: 0.0533\n",
      "Epoch 434/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1121 - val_loss: 0.0557\n",
      "Epoch 435/1024\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1108 - val_loss: 0.0642\n",
      "Epoch 436/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1117 - val_loss: 0.0551\n",
      "Epoch 437/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1104 - val_loss: 0.0544\n",
      "Epoch 438/1024\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1105 - val_loss: 0.0627\n",
      "Epoch 439/1024\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1105 - val_loss: 0.0575\n",
      "Epoch 440/1024\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1095 - val_loss: 0.0538\n",
      "Epoch 441/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1099 - val_loss: 0.0599\n",
      "Epoch 442/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1092 - val_loss: 0.0595\n",
      "Epoch 443/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1089 - val_loss: 0.0538\n",
      "Epoch 444/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1090 - val_loss: 0.0575\n",
      "Epoch 445/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1082 - val_loss: 0.0604\n",
      "Epoch 446/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1083 - val_loss: 0.0543\n",
      "Epoch 447/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1080 - val_loss: 0.0561\n",
      "Epoch 448/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1075 - val_loss: 0.0605\n",
      "Epoch 449/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1076 - val_loss: 0.0550\n",
      "Epoch 450/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1071 - val_loss: 0.0553\n",
      "Epoch 451/1024\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1067 - val_loss: 0.0599\n",
      "Epoch 452/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1067 - val_loss: 0.0554\n",
      "Epoch 453/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1062 - val_loss: 0.0550\n",
      "Epoch 454/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1060 - val_loss: 0.0594\n",
      "Epoch 455/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1059 - val_loss: 0.0558\n",
      "Epoch 456/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1054 - val_loss: 0.0551\n",
      "Epoch 457/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1052 - val_loss: 0.0592\n",
      "Epoch 458/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1051 - val_loss: 0.0559\n",
      "Epoch 459/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1047 - val_loss: 0.0553\n",
      "Epoch 460/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1044 - val_loss: 0.0590\n",
      "Epoch 461/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1043 - val_loss: 0.0557\n",
      "Epoch 462/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1039 - val_loss: 0.0557\n",
      "Epoch 463/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1036 - val_loss: 0.0587\n",
      "Epoch 464/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1035 - val_loss: 0.0555\n",
      "Epoch 465/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1031 - val_loss: 0.0565\n",
      "Epoch 466/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1028 - val_loss: 0.0586\n",
      "Epoch 467/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1026 - val_loss: 0.0555\n",
      "Epoch 468/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1024 - val_loss: 0.0576\n",
      "Epoch 469/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1021 - val_loss: 0.0581\n",
      "Epoch 470/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1018 - val_loss: 0.0558\n",
      "Epoch 471/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1016 - val_loss: 0.0586\n",
      "Epoch 472/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1013 - val_loss: 0.0572\n",
      "Epoch 473/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1010 - val_loss: 0.0566\n",
      "Epoch 474/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1008 - val_loss: 0.0590\n",
      "Epoch 475/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1005 - val_loss: 0.0566\n",
      "Epoch 476/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1002 - val_loss: 0.0582\n",
      "Epoch 477/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0999 - val_loss: 0.0585\n",
      "Epoch 478/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0997 - val_loss: 0.0570\n",
      "Epoch 479/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0994 - val_loss: 0.0595\n",
      "Epoch 480/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0992 - val_loss: 0.0574\n",
      "Epoch 481/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0989 - val_loss: 0.0587\n",
      "Epoch 482/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0986 - val_loss: 0.0589\n",
      "Epoch 483/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0983 - val_loss: 0.0579\n",
      "Epoch 484/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0981 - val_loss: 0.0600\n",
      "Epoch 485/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0978 - val_loss: 0.0579\n",
      "Epoch 486/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0975 - val_loss: 0.0602\n",
      "Epoch 487/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0972 - val_loss: 0.0587\n",
      "Epoch 488/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0970 - val_loss: 0.0599\n",
      "Epoch 489/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0967 - val_loss: 0.0598\n",
      "Epoch 490/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0964 - val_loss: 0.0596\n",
      "Epoch 491/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0961 - val_loss: 0.0608\n",
      "Epoch 492/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0958 - val_loss: 0.0594\n",
      "Epoch 493/1024\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0956 - val_loss: 0.0618\n",
      "Epoch 494/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0953 - val_loss: 0.0591\n",
      "Epoch 495/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0950 - val_loss: 0.0633\n",
      "Epoch 496/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0948 - val_loss: 0.0582\n",
      "Epoch 497/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0946 - val_loss: 0.0661\n",
      "Epoch 498/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0944 - val_loss: 0.0558\n",
      "Epoch 499/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0944 - val_loss: 0.0729\n",
      "Epoch 500/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0948 - val_loss: 0.0516\n",
      "Epoch 501/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0957 - val_loss: 0.0847\n",
      "Epoch 502/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0968 - val_loss: 0.0497\n",
      "Epoch 503/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0968 - val_loss: 0.0774\n",
      "Epoch 504/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0943 - val_loss: 0.0618\n",
      "Epoch 505/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0923 - val_loss: 0.0551\n",
      "Epoch 506/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0931 - val_loss: 0.0810\n",
      "Epoch 507/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0942 - val_loss: 0.0542\n",
      "Epoch 508/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0930 - val_loss: 0.0656\n",
      "Epoch 509/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0913 - val_loss: 0.0733\n",
      "Epoch 510/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0917 - val_loss: 0.0540\n",
      "Epoch 511/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0924 - val_loss: 0.0742\n",
      "Epoch 512/1024\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0913 - val_loss: 0.0647\n",
      "Epoch 513/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0903 - val_loss: 0.0576\n",
      "Epoch 514/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0907 - val_loss: 0.0771\n",
      "Epoch 515/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0909 - val_loss: 0.0594\n",
      "Epoch 516/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0900 - val_loss: 0.0646\n",
      "Epoch 517/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0893 - val_loss: 0.0741\n",
      "Epoch 518/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0896 - val_loss: 0.0582\n",
      "Epoch 519/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0896 - val_loss: 0.0722\n",
      "Epoch 520/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0888 - val_loss: 0.0676\n",
      "Epoch 521/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0883 - val_loss: 0.0611\n",
      "Epoch 522/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0884 - val_loss: 0.0757\n",
      "Epoch 523/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0884 - val_loss: 0.0623\n",
      "Epoch 524/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0878 - val_loss: 0.0680\n",
      "Epoch 525/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0873 - val_loss: 0.0723\n",
      "Epoch 526/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0872 - val_loss: 0.0618\n",
      "Epoch 527/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0872 - val_loss: 0.0748\n",
      "Epoch 528/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0869 - val_loss: 0.0656\n",
      "Epoch 529/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0864 - val_loss: 0.0677\n",
      "Epoch 530/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0860 - val_loss: 0.0735\n",
      "Epoch 531/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0859 - val_loss: 0.0637\n",
      "Epoch 532/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0858 - val_loss: 0.0751\n",
      "Epoch 533/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0855 - val_loss: 0.0666\n",
      "Epoch 534/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0851 - val_loss: 0.0703\n",
      "Epoch 535/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0848 - val_loss: 0.0727\n",
      "Epoch 536/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0845 - val_loss: 0.0662\n",
      "Epoch 537/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0844 - val_loss: 0.0761\n",
      "Epoch 538/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0842 - val_loss: 0.0662\n",
      "Epoch 539/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0839 - val_loss: 0.0752\n",
      "Epoch 540/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0836 - val_loss: 0.0691\n",
      "Epoch 541/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0832 - val_loss: 0.0722\n",
      "Epoch 542/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0829 - val_loss: 0.0729\n",
      "Epoch 543/1024\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0827 - val_loss: 0.0696\n",
      "Epoch 544/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0825 - val_loss: 0.0763\n",
      "Epoch 545/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0822 - val_loss: 0.0681\n",
      "Epoch 546/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0820 - val_loss: 0.0792\n",
      "Epoch 547/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0819 - val_loss: 0.0668\n",
      "Epoch 548/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0817 - val_loss: 0.0826\n",
      "Epoch 549/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0816 - val_loss: 0.0649\n",
      "Epoch 550/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0815 - val_loss: 0.0876\n",
      "Epoch 551/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0815 - val_loss: 0.0620\n",
      "Epoch 552/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0817 - val_loss: 0.0940\n",
      "Epoch 553/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0819 - val_loss: 0.0601\n",
      "Epoch 554/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0819 - val_loss: 0.0958\n",
      "Epoch 555/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0815 - val_loss: 0.0635\n",
      "Epoch 556/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0806 - val_loss: 0.0854\n",
      "Epoch 557/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0795 - val_loss: 0.0754\n",
      "Epoch 558/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0788 - val_loss: 0.0720\n",
      "Epoch 559/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0787 - val_loss: 0.0888\n",
      "Epoch 560/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0790 - val_loss: 0.0659\n",
      "Epoch 561/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0792 - val_loss: 0.0933\n",
      "Epoch 562/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0790 - val_loss: 0.0684\n",
      "Epoch 563/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0783 - val_loss: 0.0859\n",
      "Epoch 564/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0776 - val_loss: 0.0779\n",
      "Epoch 565/1024\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0771 - val_loss: 0.0757\n",
      "Epoch 566/1024\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0769 - val_loss: 0.0882\n",
      "Epoch 567/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0770 - val_loss: 0.0704\n",
      "Epoch 568/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0770 - val_loss: 0.0935\n",
      "Epoch 569/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0769 - val_loss: 0.0709\n",
      "Epoch 570/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0766 - val_loss: 0.0916\n",
      "Epoch 571/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0761 - val_loss: 0.0761\n",
      "Epoch 572/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0756 - val_loss: 0.0851\n",
      "Epoch 573/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0751 - val_loss: 0.0835\n",
      "Epoch 574/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0748 - val_loss: 0.0794\n",
      "Epoch 575/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0747 - val_loss: 0.0904\n",
      "Epoch 576/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0746 - val_loss: 0.0759\n",
      "Epoch 577/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0745 - val_loss: 0.0958\n",
      "Epoch 578/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0744 - val_loss: 0.0738\n",
      "Epoch 579/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0744 - val_loss: 0.0998\n",
      "Epoch 580/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0743 - val_loss: 0.0729\n",
      "Epoch 581/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0741 - val_loss: 0.1021\n",
      "Epoch 582/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0739 - val_loss: 0.0738\n",
      "Epoch 583/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0736 - val_loss: 0.1012\n",
      "Epoch 584/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0732 - val_loss: 0.0775\n",
      "Epoch 585/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0727 - val_loss: 0.0968\n",
      "Epoch 586/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0722 - val_loss: 0.0836\n",
      "Epoch 587/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0717 - val_loss: 0.0914\n",
      "Epoch 588/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0714 - val_loss: 0.0903\n",
      "Epoch 589/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0711 - val_loss: 0.0870\n",
      "Epoch 590/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0709 - val_loss: 0.0965\n",
      "Epoch 591/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0708 - val_loss: 0.0835\n",
      "Epoch 592/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0707 - val_loss: 0.1028\n",
      "Epoch 593/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0707 - val_loss: 0.0794\n",
      "Epoch 594/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0708 - val_loss: 0.1113\n",
      "Epoch 595/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0710 - val_loss: 0.0743\n",
      "Epoch 596/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0715 - val_loss: 0.1222\n",
      "Epoch 597/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0721 - val_loss: 0.0712\n",
      "Epoch 598/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0723 - val_loss: 0.1244\n",
      "Epoch 599/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0717 - val_loss: 0.0782\n",
      "Epoch 600/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0702 - val_loss: 0.1053\n",
      "Epoch 601/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0686 - val_loss: 0.0993\n",
      "Epoch 602/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0681 - val_loss: 0.0851\n",
      "Epoch 603/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0685 - val_loss: 0.1185\n",
      "Epoch 604/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0691 - val_loss: 0.0805\n",
      "Epoch 605/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0691 - val_loss: 0.1162\n",
      "Epoch 606/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0682 - val_loss: 0.0922\n",
      "Epoch 607/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0671 - val_loss: 0.0982\n",
      "Epoch 608/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0667 - val_loss: 0.1106\n",
      "Epoch 609/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0668 - val_loss: 0.0866\n",
      "Epoch 610/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0672 - val_loss: 0.1189\n",
      "Epoch 611/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0671 - val_loss: 0.0890\n",
      "Epoch 612/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0665 - val_loss: 0.1114\n",
      "Epoch 613/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0658 - val_loss: 0.1019\n",
      "Epoch 614/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0653 - val_loss: 0.0990\n",
      "Epoch 615/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0652 - val_loss: 0.1151\n",
      "Epoch 616/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0652 - val_loss: 0.0928\n",
      "Epoch 617/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0653 - val_loss: 0.1202\n",
      "Epoch 618/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0651 - val_loss: 0.0949\n",
      "Epoch 619/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0647 - val_loss: 0.1164\n",
      "Epoch 620/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0642 - val_loss: 0.1028\n",
      "Epoch 621/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0638 - val_loss: 0.1086\n",
      "Epoch 622/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0635 - val_loss: 0.1121\n",
      "Epoch 623/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0633 - val_loss: 0.1025\n",
      "Epoch 624/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0632 - val_loss: 0.1196\n",
      "Epoch 625/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0631 - val_loss: 0.0995\n",
      "Epoch 626/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0631 - val_loss: 0.1247\n",
      "Epoch 627/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0630 - val_loss: 0.0988\n",
      "Epoch 628/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0628 - val_loss: 0.1274\n",
      "Epoch 629/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0626 - val_loss: 0.0994\n",
      "Epoch 630/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0624 - val_loss: 0.1281\n",
      "Epoch 631/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0621 - val_loss: 0.1013\n",
      "Epoch 632/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0619 - val_loss: 0.1279\n",
      "Epoch 633/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0616 - val_loss: 0.1043\n",
      "Epoch 634/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0613 - val_loss: 0.1275\n",
      "Epoch 635/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0610 - val_loss: 0.1073\n",
      "Epoch 636/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0607 - val_loss: 0.1272\n",
      "Epoch 637/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0604 - val_loss: 0.1095\n",
      "Epoch 638/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0601 - val_loss: 0.1280\n",
      "Epoch 639/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0599 - val_loss: 0.1104\n",
      "Epoch 640/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0597 - val_loss: 0.1309\n",
      "Epoch 641/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0596 - val_loss: 0.1093\n",
      "Epoch 642/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0595 - val_loss: 0.1369\n",
      "Epoch 643/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0595 - val_loss: 0.1050\n",
      "Epoch 644/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0596 - val_loss: 0.1479\n",
      "Epoch 645/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0601 - val_loss: 0.0973\n",
      "Epoch 646/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0609 - val_loss: 0.1644\n",
      "Epoch 647/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0620 - val_loss: 0.0908\n",
      "Epoch 648/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0629 - val_loss: 0.1701\n",
      "Epoch 649/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0624 - val_loss: 0.0992\n",
      "Epoch 650/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0602 - val_loss: 0.1407\n",
      "Epoch 651/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0577 - val_loss: 0.1315\n",
      "Epoch 652/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0569 - val_loss: 0.1081\n",
      "Epoch 653/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0580 - val_loss: 0.1592\n",
      "Epoch 654/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0591 - val_loss: 0.1038\n",
      "Epoch 655/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0586 - val_loss: 0.1478\n",
      "Epoch 656/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0570 - val_loss: 0.1275\n",
      "Epoch 657/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0559 - val_loss: 0.1187\n",
      "Epoch 658/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0561 - val_loss: 0.1532\n",
      "Epoch 659/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0568 - val_loss: 0.1096\n",
      "Epoch 660/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0569 - val_loss: 0.1493\n",
      "Epoch 661/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0560 - val_loss: 0.1251\n",
      "Epoch 662/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0550 - val_loss: 0.1271\n",
      "Epoch 663/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0547 - val_loss: 0.1477\n",
      "Epoch 664/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0550 - val_loss: 0.1157\n",
      "Epoch 665/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0553 - val_loss: 0.1523\n",
      "Epoch 666/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0549 - val_loss: 0.1226\n",
      "Epoch 667/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0542 - val_loss: 0.1383\n",
      "Epoch 668/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0536 - val_loss: 0.1394\n",
      "Epoch 669/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0535 - val_loss: 0.1244\n",
      "Epoch 670/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0536 - val_loss: 0.1510\n",
      "Epoch 671/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0536 - val_loss: 0.1214\n",
      "Epoch 672/1024\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0535 - val_loss: 0.1497\n",
      "Epoch 673/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0531 - val_loss: 0.1283\n",
      "Epoch 674/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0526 - val_loss: 0.1398\n",
      "Epoch 675/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0522 - val_loss: 0.1392\n",
      "Epoch 676/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0520 - val_loss: 0.1306\n",
      "Epoch 677/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0519 - val_loss: 0.1481\n",
      "Epoch 678/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0518 - val_loss: 0.1261\n",
      "Epoch 679/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0518 - val_loss: 0.1520\n",
      "Epoch 680/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0516 - val_loss: 0.1259\n",
      "Epoch 681/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0514 - val_loss: 0.1514\n",
      "Epoch 682/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0511 - val_loss: 0.1282\n",
      "Epoch 683/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0508 - val_loss: 0.1486\n",
      "Epoch 684/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0505 - val_loss: 0.1318\n",
      "Epoch 685/1024\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0501 - val_loss: 0.1458\n",
      "Epoch 686/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0498 - val_loss: 0.1350\n",
      "Epoch 687/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0496 - val_loss: 0.1441\n",
      "Epoch 688/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0493 - val_loss: 0.1372\n",
      "Epoch 689/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0491 - val_loss: 0.1437\n",
      "Epoch 690/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0489 - val_loss: 0.1357\n",
      "Epoch 691/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0487 - val_loss: 0.1457\n",
      "Epoch 692/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0485 - val_loss: 0.1340\n",
      "Epoch 693/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0483 - val_loss: 0.1525\n",
      "Epoch 694/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0483 - val_loss: 0.1283\n",
      "Epoch 695/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0484 - val_loss: 0.1657\n",
      "Epoch 696/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0489 - val_loss: 0.1146\n",
      "Epoch 697/1024\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0502 - val_loss: 0.1966\n",
      "Epoch 698/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0532 - val_loss: 0.0940\n",
      "Epoch 699/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0579 - val_loss: 0.2362\n",
      "Epoch 700/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0622 - val_loss: 0.0932\n",
      "Epoch 701/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0584 - val_loss: 0.1801\n",
      "Epoch 702/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0491 - val_loss: 0.1609\n",
      "Epoch 703/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0469 - val_loss: 0.1033\n",
      "Epoch 704/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0526 - val_loss: 0.2057\n",
      "Epoch 705/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0535 - val_loss: 0.1243\n",
      "Epoch 706/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0473 - val_loss: 0.1301\n",
      "Epoch 707/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0465 - val_loss: 0.1972\n",
      "Epoch 708/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0506 - val_loss: 0.1159\n",
      "Epoch 709/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0490 - val_loss: 0.1545\n",
      "Epoch 710/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0453 - val_loss: 0.1787\n",
      "Epoch 711/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0470 - val_loss: 0.1163\n",
      "Epoch 712/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0485 - val_loss: 0.1700\n",
      "Epoch 713/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0457 - val_loss: 0.1597\n",
      "Epoch 714/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0448 - val_loss: 0.1216\n",
      "Epoch 715/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0468 - val_loss: 0.1782\n",
      "Epoch 716/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0461 - val_loss: 0.1451\n",
      "Epoch 717/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0441 - val_loss: 0.1327\n",
      "Epoch 718/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0448 - val_loss: 0.1802\n",
      "Epoch 719/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0456 - val_loss: 0.1365\n",
      "Epoch 720/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0442 - val_loss: 0.1472\n",
      "Epoch 721/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0435 - val_loss: 0.1740\n",
      "Epoch 722/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0443 - val_loss: 0.1324\n",
      "Epoch 723/1024\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0442 - val_loss: 0.1612\n",
      "Epoch 724/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0431 - val_loss: 0.1619\n",
      "Epoch 725/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0430 - val_loss: 0.1356\n",
      "Epoch 726/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0435 - val_loss: 0.1706\n",
      "Epoch 727/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0431 - val_loss: 0.1487\n",
      "Epoch 728/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0424 - val_loss: 0.1445\n",
      "Epoch 729/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0423 - val_loss: 0.1694\n",
      "Epoch 730/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0426 - val_loss: 0.1399\n",
      "Epoch 731/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0423 - val_loss: 0.1571\n",
      "Epoch 732/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0417 - val_loss: 0.1603\n",
      "Epoch 733/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0416 - val_loss: 0.1411\n",
      "Epoch 734/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0418 - val_loss: 0.1663\n",
      "Epoch 735/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0416 - val_loss: 0.1487\n",
      "Epoch 736/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0411 - val_loss: 0.1507\n",
      "Epoch 737/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0409 - val_loss: 0.1640\n",
      "Epoch 738/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0410 - val_loss: 0.1435\n",
      "Epoch 739/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0409 - val_loss: 0.1620\n",
      "Epoch 740/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0406 - val_loss: 0.1534\n",
      "Epoch 741/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0403 - val_loss: 0.1496\n",
      "Epoch 742/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0402 - val_loss: 0.1637\n",
      "Epoch 743/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0402 - val_loss: 0.1465\n",
      "Epoch 744/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0400 - val_loss: 0.1607\n",
      "Epoch 745/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0398 - val_loss: 0.1550\n",
      "Epoch 746/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0395 - val_loss: 0.1517\n",
      "Epoch 747/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0394 - val_loss: 0.1630\n",
      "Epoch 748/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0394 - val_loss: 0.1490\n",
      "Epoch 749/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0392 - val_loss: 0.1621\n",
      "Epoch 750/1024\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0390 - val_loss: 0.1543\n",
      "Epoch 751/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0388 - val_loss: 0.1557\n",
      "Epoch 752/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0387 - val_loss: 0.1611\n",
      "Epoch 753/1024\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0385 - val_loss: 0.1514\n",
      "Epoch 754/1024\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0384 - val_loss: 0.1632\n",
      "Epoch 755/1024\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0383 - val_loss: 0.1525\n",
      "Epoch 756/1024\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0381 - val_loss: 0.1606\n",
      "Epoch 757/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0379 - val_loss: 0.1570\n",
      "Epoch 758/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0378 - val_loss: 0.1566\n",
      "Epoch 759/1024\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0376 - val_loss: 0.1614\n",
      "Epoch 760/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0375 - val_loss: 0.1540\n",
      "Epoch 761/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0374 - val_loss: 0.1634\n",
      "Epoch 762/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0372 - val_loss: 0.1538\n",
      "Epoch 763/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0371 - val_loss: 0.1635\n",
      "Epoch 764/1024\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0369 - val_loss: 0.1553\n",
      "Epoch 765/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0368 - val_loss: 0.1623\n",
      "Epoch 766/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0366 - val_loss: 0.1573\n",
      "Epoch 767/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0365 - val_loss: 0.1609\n",
      "Epoch 768/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0363 - val_loss: 0.1591\n",
      "Epoch 769/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0362 - val_loss: 0.1597\n",
      "Epoch 770/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0360 - val_loss: 0.1606\n",
      "Epoch 771/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0359 - val_loss: 0.1586\n",
      "Epoch 772/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0358 - val_loss: 0.1620\n",
      "Epoch 773/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0356 - val_loss: 0.1575\n",
      "Epoch 774/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0355 - val_loss: 0.1638\n",
      "Epoch 775/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0354 - val_loss: 0.1556\n",
      "Epoch 776/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0353 - val_loss: 0.1669\n",
      "Epoch 777/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0352 - val_loss: 0.1519\n",
      "Epoch 778/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0351 - val_loss: 0.1733\n",
      "Epoch 779/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0351 - val_loss: 0.1440\n",
      "Epoch 780/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0353 - val_loss: 0.1877\n",
      "Epoch 781/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0359 - val_loss: 0.1279\n",
      "Epoch 782/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0374 - val_loss: 0.2200\n",
      "Epoch 783/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0403 - val_loss: 0.1031\n",
      "Epoch 784/1024\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0453 - val_loss: 0.2674\n",
      "Epoch 785/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0508 - val_loss: 0.0949\n",
      "Epoch 786/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0501 - val_loss: 0.2314\n",
      "Epoch 787/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0413 - val_loss: 0.1568\n",
      "Epoch 788/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0339 - val_loss: 0.1284\n",
      "Epoch 789/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0372 - val_loss: 0.2400\n",
      "Epoch 790/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0427 - val_loss: 0.1202\n",
      "Epoch 791/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0393 - val_loss: 0.1777\n",
      "Epoch 792/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0336 - val_loss: 0.2026\n",
      "Epoch 793/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0356 - val_loss: 0.1217\n",
      "Epoch 794/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0390 - val_loss: 0.2069\n",
      "Epoch 795/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0360 - val_loss: 0.1671\n",
      "Epoch 796/1024\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0330 - val_loss: 0.1342\n",
      "Epoch 797/1024\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0354 - val_loss: 0.2105\n",
      "Epoch 798/1024\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0366 - val_loss: 0.1439\n",
      "Epoch 799/1024\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0336 - val_loss: 0.1525\n",
      "Epoch 800/1024\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0328 - val_loss: 0.1996\n",
      "Epoch 801/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0349 - val_loss: 0.1346\n",
      "Epoch 802/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0344 - val_loss: 0.1727\n",
      "Epoch 803/1024\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0324 - val_loss: 0.1819\n",
      "Epoch 804/1024\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0327 - val_loss: 0.1364\n",
      "Epoch 805/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0339 - val_loss: 0.1873\n",
      "Epoch 806/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0329 - val_loss: 0.1629\n",
      "Epoch 807/1024\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0318 - val_loss: 0.1459\n",
      "Epoch 808/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0324 - val_loss: 0.1898\n",
      "Epoch 809/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0329 - val_loss: 0.1481\n",
      "Epoch 810/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0320 - val_loss: 0.1610\n",
      "Epoch 811/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0314 - val_loss: 0.1805\n",
      "Epoch 812/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0319 - val_loss: 0.1431\n",
      "Epoch 813/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0321 - val_loss: 0.1754\n",
      "Epoch 814/1024\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0314 - val_loss: 0.1643\n",
      "Epoch 815/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0309 - val_loss: 0.1489\n",
      "Epoch 816/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0312 - val_loss: 0.1803\n",
      "Epoch 817/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0314 - val_loss: 0.1512\n",
      "Epoch 818/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0309 - val_loss: 0.1631\n",
      "Epoch 819/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0305 - val_loss: 0.1731\n",
      "Epoch 820/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0306 - val_loss: 0.1491\n",
      "Epoch 821/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0308 - val_loss: 0.1751\n",
      "Epoch 822/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0305 - val_loss: 0.1594\n",
      "Epoch 823/1024\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0301 - val_loss: 0.1581\n",
      "Epoch 824/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0301 - val_loss: 0.1745\n",
      "Epoch 825/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0302 - val_loss: 0.1523\n",
      "Epoch 826/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0301 - val_loss: 0.1709\n",
      "Epoch 827/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0298 - val_loss: 0.1636\n",
      "Epoch 828/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0296 - val_loss: 0.1581\n",
      "Epoch 829/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0296 - val_loss: 0.1738\n",
      "Epoch 830/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0296 - val_loss: 0.1556\n",
      "Epoch 831/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0295 - val_loss: 0.1696\n",
      "Epoch 832/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0293 - val_loss: 0.1647\n",
      "Epoch 833/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0291 - val_loss: 0.1599\n",
      "Epoch 834/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0290 - val_loss: 0.1722\n",
      "Epoch 835/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0290 - val_loss: 0.1574\n",
      "Epoch 836/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0289 - val_loss: 0.1698\n",
      "Epoch 837/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0288 - val_loss: 0.1633\n",
      "Epoch 838/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0286 - val_loss: 0.1624\n",
      "Epoch 839/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0285 - val_loss: 0.1698\n",
      "Epoch 840/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0284 - val_loss: 0.1587\n",
      "Epoch 841/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0284 - val_loss: 0.1704\n",
      "Epoch 842/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0283 - val_loss: 0.1611\n",
      "Epoch 843/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0281 - val_loss: 0.1660\n",
      "Epoch 844/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0280 - val_loss: 0.1662\n",
      "Epoch 845/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0279 - val_loss: 0.1615\n",
      "Epoch 846/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0278 - val_loss: 0.1695\n",
      "Epoch 847/1024\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0277 - val_loss: 0.1600\n",
      "Epoch 848/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0276 - val_loss: 0.1690\n",
      "Epoch 849/1024\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0275 - val_loss: 0.1616\n",
      "Epoch 850/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0274 - val_loss: 0.1662\n",
      "Epoch 851/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0273 - val_loss: 0.1646\n",
      "Epoch 852/1024\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0272 - val_loss: 0.1632\n",
      "Epoch 853/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0271 - val_loss: 0.1671\n",
      "Epoch 854/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0270 - val_loss: 0.1612\n",
      "Epoch 855/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0269 - val_loss: 0.1683\n",
      "Epoch 856/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0268 - val_loss: 0.1604\n",
      "Epoch 857/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0267 - val_loss: 0.1683\n",
      "Epoch 858/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0266 - val_loss: 0.1603\n",
      "Epoch 859/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0265 - val_loss: 0.1678\n",
      "Epoch 860/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0264 - val_loss: 0.1606\n",
      "Epoch 861/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0263 - val_loss: 0.1673\n",
      "Epoch 862/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0262 - val_loss: 0.1606\n",
      "Epoch 863/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0261 - val_loss: 0.1672\n",
      "Epoch 864/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0260 - val_loss: 0.1602\n",
      "Epoch 865/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0259 - val_loss: 0.1677\n",
      "Epoch 866/1024\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0259 - val_loss: 0.1590\n",
      "Epoch 867/1024\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0258 - val_loss: 0.1693\n",
      "Epoch 868/1024\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0257 - val_loss: 0.1563\n",
      "Epoch 869/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0256 - val_loss: 0.1731\n",
      "Epoch 870/1024\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0256 - val_loss: 0.1508\n",
      "Epoch 871/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0256 - val_loss: 0.1815\n",
      "Epoch 872/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0258 - val_loss: 0.1397\n",
      "Epoch 873/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0263 - val_loss: 0.2004\n",
      "Epoch 874/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0273 - val_loss: 0.1191\n",
      "Epoch 875/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0295 - val_loss: 0.2410\n",
      "Epoch 876/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0915\n",
      "Epoch 877/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0397 - val_loss: 0.2911\n",
      "Epoch 878/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0452 - val_loss: 0.0884\n",
      "Epoch 879/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0422 - val_loss: 0.2346\n",
      "Epoch 880/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0314 - val_loss: 0.1652\n",
      "Epoch 881/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0246 - val_loss: 0.1219\n",
      "Epoch 882/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0293 - val_loss: 0.2541\n",
      "Epoch 883/1024\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0350 - val_loss: 0.1173\n",
      "Epoch 884/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0306 - val_loss: 0.1803\n",
      "Epoch 885/1024\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0245 - val_loss: 0.2093\n",
      "Epoch 886/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0268 - val_loss: 0.1171\n",
      "Epoch 887/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0306 - val_loss: 0.2160\n",
      "Epoch 888/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0277 - val_loss: 0.1644\n",
      "Epoch 889/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0240 - val_loss: 0.1338\n",
      "Epoch 890/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0263 - val_loss: 0.2186\n",
      "Epoch 891/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0283 - val_loss: 0.1377\n",
      "Epoch 892/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0254 - val_loss: 0.1587\n",
      "Epoch 893/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0238 - val_loss: 0.2011\n",
      "Epoch 894/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0259 - val_loss: 0.1294\n",
      "Epoch 895/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0263 - val_loss: 0.1827\n",
      "Epoch 896/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0241 - val_loss: 0.1763\n",
      "Epoch 897/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0237 - val_loss: 0.1353\n",
      "Epoch 898/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0251 - val_loss: 0.1954\n",
      "Epoch 899/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0249 - val_loss: 0.1538\n",
      "Epoch 900/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0233 - val_loss: 0.1500\n",
      "Epoch 901/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0234 - val_loss: 0.1906\n",
      "Epoch 902/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0244 - val_loss: 0.1399\n",
      "Epoch 903/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0239 - val_loss: 0.1679\n",
      "Epoch 904/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0229 - val_loss: 0.1734\n",
      "Epoch 905/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0230 - val_loss: 0.1396\n",
      "Epoch 906/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0236 - val_loss: 0.1802\n",
      "Epoch 907/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0233 - val_loss: 0.1539\n",
      "Epoch 908/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0226 - val_loss: 0.1510\n",
      "Epoch 909/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0226 - val_loss: 0.1779\n",
      "Epoch 910/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0230 - val_loss: 0.1430\n",
      "Epoch 911/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0228 - val_loss: 0.1672\n",
      "Epoch 912/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0223 - val_loss: 0.1634\n",
      "Epoch 913/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0222 - val_loss: 0.1464\n",
      "Epoch 914/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0224 - val_loss: 0.1746\n",
      "Epoch 915/1024\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0224 - val_loss: 0.1488\n",
      "Epoch 916/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0221 - val_loss: 0.1598\n",
      "Epoch 917/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0218 - val_loss: 0.1659\n",
      "Epoch 918/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0219 - val_loss: 0.1467\n",
      "Epoch 919/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0220 - val_loss: 0.1702\n",
      "Epoch 920/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0219 - val_loss: 0.1523\n",
      "Epoch 921/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0216 - val_loss: 0.1578\n",
      "Epoch 922/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0214 - val_loss: 0.1654\n",
      "Epoch 923/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0215 - val_loss: 0.1489\n",
      "Epoch 924/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0215 - val_loss: 0.1678\n",
      "Epoch 925/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0214 - val_loss: 0.1533\n",
      "Epoch 926/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0212 - val_loss: 0.1586\n",
      "Epoch 927/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0211 - val_loss: 0.1631\n",
      "Epoch 928/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0210 - val_loss: 0.1511\n",
      "Epoch 929/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0210 - val_loss: 0.1662\n",
      "Epoch 930/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0209 - val_loss: 0.1527\n",
      "Epoch 931/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0208 - val_loss: 0.1607\n",
      "Epoch 932/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0207 - val_loss: 0.1599\n",
      "Epoch 933/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0206 - val_loss: 0.1541\n",
      "Epoch 934/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0206 - val_loss: 0.1645\n",
      "Epoch 935/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0205 - val_loss: 0.1524\n",
      "Epoch 936/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0204 - val_loss: 0.1630\n",
      "Epoch 937/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0203 - val_loss: 0.1559\n",
      "Epoch 938/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0202 - val_loss: 0.1580\n",
      "Epoch 939/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0201 - val_loss: 0.1605\n",
      "Epoch 940/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0201 - val_loss: 0.1540\n",
      "Epoch 941/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0200 - val_loss: 0.1626\n",
      "Epoch 942/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0200 - val_loss: 0.1531\n",
      "Epoch 943/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0199 - val_loss: 0.1616\n",
      "Epoch 944/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0198 - val_loss: 0.1548\n",
      "Epoch 945/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0197 - val_loss: 0.1588\n",
      "Epoch 946/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0196 - val_loss: 0.1575\n",
      "Epoch 947/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0195 - val_loss: 0.1559\n",
      "Epoch 948/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0195 - val_loss: 0.1597\n",
      "Epoch 949/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0194 - val_loss: 0.1539\n",
      "Epoch 950/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0193 - val_loss: 0.1607\n",
      "Epoch 951/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0193 - val_loss: 0.1529\n",
      "Epoch 952/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0192 - val_loss: 0.1608\n",
      "Epoch 953/1024\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0191 - val_loss: 0.1527\n",
      "Epoch 954/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0191 - val_loss: 0.1606\n",
      "Epoch 955/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0190 - val_loss: 0.1527\n",
      "Epoch 956/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0189 - val_loss: 0.1603\n",
      "Epoch 957/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0188 - val_loss: 0.1524\n",
      "Epoch 958/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0188 - val_loss: 0.1605\n",
      "Epoch 959/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0187 - val_loss: 0.1516\n",
      "Epoch 960/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0186 - val_loss: 0.1615\n",
      "Epoch 961/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0186 - val_loss: 0.1498\n",
      "Epoch 962/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0185 - val_loss: 0.1638\n",
      "Epoch 963/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0185 - val_loss: 0.1462\n",
      "Epoch 964/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0185 - val_loss: 0.1690\n",
      "Epoch 965/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0185 - val_loss: 0.1393\n",
      "Epoch 966/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0187 - val_loss: 0.1801\n",
      "Epoch 967/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0191 - val_loss: 0.1261\n",
      "Epoch 968/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0199 - val_loss: 0.2038\n",
      "Epoch 969/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0215 - val_loss: 0.1038\n",
      "Epoch 970/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0245 - val_loss: 0.2497\n",
      "Epoch 971/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0296 - val_loss: 0.0791\n",
      "Epoch 972/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0357 - val_loss: 0.2912\n",
      "Epoch 973/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0395 - val_loss: 0.0842\n",
      "Epoch 974/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0335 - val_loss: 0.2170\n",
      "Epoch 975/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0224 - val_loss: 0.1668\n",
      "Epoch 976/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0177 - val_loss: 0.1118\n",
      "Epoch 977/1024\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0231 - val_loss: 0.2492\n",
      "Epoch 978/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0282 - val_loss: 0.1096\n",
      "Epoch 979/1024\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0238 - val_loss: 0.1773\n",
      "Epoch 980/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0178 - val_loss: 0.1965\n",
      "Epoch 981/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0193 - val_loss: 0.1104\n",
      "Epoch 982/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0235 - val_loss: 0.2164\n",
      "Epoch 983/1024\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0220 - val_loss: 0.1440\n",
      "Epoch 984/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0177 - val_loss: 0.1358\n",
      "Epoch 985/1024\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0182 - val_loss: 0.2086\n",
      "Epoch 986/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0212 - val_loss: 0.1198\n",
      "Epoch 987/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0202 - val_loss: 0.1699\n",
      "Epoch 988/1024\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0173 - val_loss: 0.1763\n",
      "Epoch 989/1024\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0176 - val_loss: 0.1214\n",
      "Epoch 990/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0195 - val_loss: 0.1915\n",
      "Epoch 991/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0189 - val_loss: 0.1452\n",
      "Epoch 992/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0170 - val_loss: 0.1407\n",
      "Epoch 993/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0171 - val_loss: 0.1883\n",
      "Epoch 994/1024\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0184 - val_loss: 0.1291\n",
      "Epoch 995/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0180 - val_loss: 0.1652\n",
      "Epoch 996/1024\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0167 - val_loss: 0.1655\n",
      "Epoch 997/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0167 - val_loss: 0.1308\n",
      "Epoch 998/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0175 - val_loss: 0.1789\n",
      "Epoch 999/1024\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0174 - val_loss: 0.1421\n",
      "Epoch 1000/1024\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0165 - val_loss: 0.1479\n",
      "Epoch 1001/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0163 - val_loss: 0.1719\n",
      "Epoch 1002/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0168 - val_loss: 0.1328\n",
      "Epoch 1003/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0169 - val_loss: 0.1667\n",
      "Epoch 1004/1024\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0164 - val_loss: 0.1515\n",
      "Epoch 1005/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0160 - val_loss: 0.1415\n",
      "Epoch 1006/1024\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0162 - val_loss: 0.1701\n",
      "Epoch 1007/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0164 - val_loss: 0.1377\n",
      "Epoch 1008/1024\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0162 - val_loss: 0.1595\n",
      "Epoch 1009/1024\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0158 - val_loss: 0.1554\n",
      "Epoch 1010/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0157 - val_loss: 0.1412\n",
      "Epoch 1011/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0159 - val_loss: 0.1663\n",
      "Epoch 1012/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0160 - val_loss: 0.1408\n",
      "Epoch 1013/1024\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0158 - val_loss: 0.1564\n",
      "Epoch 1014/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0155 - val_loss: 0.1549\n",
      "Epoch 1015/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0154 - val_loss: 0.1429\n",
      "Epoch 1016/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0155 - val_loss: 0.1631\n",
      "Epoch 1017/1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0155 - val_loss: 0.1423\n",
      "Epoch 1018/1024\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0154 - val_loss: 0.1563\n",
      "Epoch 1019/1024\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0152 - val_loss: 0.1523\n",
      "Epoch 1020/1024\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0151 - val_loss: 0.1457\n",
      "Epoch 1021/1024\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0151 - val_loss: 0.1599\n",
      "Epoch 1022/1024\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0152 - val_loss: 0.1430\n",
      "Epoch 1023/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0151 - val_loss: 0.1574\n",
      "Epoch 1024/1024\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0150 - val_loss: 0.1489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x205e7d74eb0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train, y_train, epochs=1024, shuffle=True, batch_size = 128, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "45859090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 3ms/step - loss: 0.0149\n",
      "Accuracy: 1.49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.asarray(x_train).astype(np.float32)\n",
    "y = np.asarray(y_train).astype(np.float32)\n",
    "\n",
    "accuracy = regressor.evaluate(x, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83aad7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regressor.predict(x_train)\n",
    "y_predict_teste = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6b70924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Accuracy: 1.49\n"
     ]
    }
   ],
   "source": [
    "accuracy = regressor.evaluate(x, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3431845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1489\n",
      "Accuracy: 14.89\n"
     ]
    }
   ],
   "source": [
    "accuracy = regressor.evaluate(x_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d358e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
